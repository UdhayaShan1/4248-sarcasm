{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pLAfJQ3W-b4E",
        "p5S3z2vu6Jwm",
        "P5Qx2QOvQhUu",
        "XxRzIp-kA6D8",
        "b3eItOu6_9bd",
        "r0uTWa2485zD",
        "KgmMswbW-Eoi",
        "-gBncVsq-NXK",
        "EIVPp6_KBKMv",
        "xY4IQwJKBgui",
        "uw9JGGO-Pdvu",
        "effM6l5dPxIx",
        "B0cmAocxOgsO",
        "CRlGez3mLNUi",
        "iicdNjIp9i01",
        "0I6_873Zwfvp",
        "MlOPkkNfpe6C",
        "MtMfH7_tMBsx"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sarcasm Classification: Comprehensive Model Exploration (Part 2)**\n",
        "\n",
        "**Author: Shanmugam Udhaya**\n",
        "\n",
        "*Contact:* [@frostbitepillars](https://t.me/frostbitepillars) for any clarifications  \n",
        "\n",
        "---\n",
        "\n",
        "In **Part 1**, we intentionally skipped text pre-processing and performed **feature ablation** on a wide set of linguistic indicators. From that, we settled on a core set of 17 linguistic features, which we’ll now treat as our standard linguistic feature set throughout this series.\n",
        "\n",
        "---\n",
        "\n",
        "## **Feature Vector and Method**\n",
        "\n",
        "For this stage, our full feature vector will consist of the following:\n",
        "\n",
        "- **TF-IDF (Unigrams)**  \n",
        "  Captures frequency-based importance of individual words.\n",
        "\n",
        "- **GloVe 300D Word Embeddings**  \n",
        "  Specifically, we use the pre-trained **GloVe 300D vectors** trained on **Wikipedia 2014 + Gigaword 5**. Each headline is represented using a **mean-pooled vector** of its tokens.\n",
        "\n",
        "- **17 Linguistic Features**  \n",
        "  Handcrafted structural, syntactic, and stylistic indicators (defined in Part 1).\n",
        "\n",
        "---\n",
        "\n",
        "To understand the value of each feature type, we will try different combinations of features:\n",
        "\n",
        "- **TF-IDF + Linguistic**\n",
        "- **GloVe + Linguistic**\n",
        "- **TF-IDF + GloVe**\n",
        "- **All Three Combined**\n",
        "\n",
        "This helps us measure how much each modality contributes to sarcasm detection and whether simpler combinations can match more complex ones.\n",
        "\n",
        "## **Model Exploration**\n",
        "\n",
        "The bulk of this notebook will comprise of trying different models which are,\n",
        "\n",
        "\n",
        "- Logistic Regression\n",
        "- Sentence Transformer to replace GloVe embeddings\n",
        "- BERT CLS to replace GloVe embeddings\n",
        "  - Non Fine Tuned\n",
        "  - Fine Tuned\n",
        "- Feed Forward Neural Network\n",
        "\n",
        " - Alternative take on Logistic Regression by using a single layer of nn.Linear(input_size, 2)\n",
        "  - One hidden layer\n",
        "- RNN\n",
        "- LSTM\n",
        " - Explore effects of using pre-trained vectors, bidirectional, number of layers, more complex projection heads, use of attention\n",
        "- LSTM w/ Features\n",
        "- LSTM w/ BERT (use BERT token embeddings instead of GloVe)\n",
        "\n",
        "\n",
        "## **Summary of Findings**\n",
        "You can find specific scores here\n",
        "\n",
        "https://docs.google.com/document/d/1m3TwS5kWPg6si5BhshMV-hWLO3y7y6ryf6-w26ARQ2Q/edit?usp=sharing\n",
        "\n",
        "Key findings include\n",
        "- BERT embeddings, specifically extracting the CLS token can be a very powerful feature.\n",
        "- Classification task is very feature driven, a Logistic Regression model can achieve close or even better results than sequential RNN/LSTM models. This is good as it gives way to possibly more insightful findings\n",
        "\n",
        "- Going forward we will spend more time on feature development such as enhancing our embeddings or expanding our linguistic set.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MU21RAMJPDGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "1nklsLHENr5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPQ52drUTFHv",
        "outputId": "4caeaaea-23dd-4e78-e3a6-ad75e748806d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsYRbMbCl3bA",
        "outputId": "c46cbbb8-667f-4c1f-a576-2623badac3bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eVjlFhPvpgXmj-wH52qAzdIUyHrfs92G\n",
            "To: /content/archive (7).zip\n",
            "\r  0% 0.00/3.46M [00:00<?, ?B/s]\r100% 3.46M/3.46M [00:00<00:00, 195MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1eVjlFhPvpgXmj-wH52qAzdIUyHrfs92G"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"archive (7).zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTPnvgBZl8OE",
        "outputId": "14709afa-322b-401b-912f-ae78a4b50ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  archive (7).zip\n",
            "  inflating: Sarcasm_Headlines_Dataset.json  \n",
            "  inflating: Sarcasm_Headlines_Dataset_v2.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\", lines=True)"
      ],
      "metadata": {
        "id": "xw8ttrdEmn92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(df.isnull().sum())\n",
        "print(Counter(df['is_sarcastic']))\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKotEXcY-Ape",
        "outputId": "c8c82c6b-4e2a-4dbe-b7f0-1ed639bceae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['is_sarcastic', 'headline', 'article_link'], dtype='object')\n",
            "is_sarcastic    0\n",
            "headline        0\n",
            "article_link    0\n",
            "dtype: int64\n",
            "Counter({0: 14985, 1: 13634})\n",
            "   is_sarcastic                                           headline  \\\n",
            "0             1  thirtysomething scientists unveil doomsday clo...   \n",
            "1             0  dem rep. totally nails why congress is falling...   \n",
            "2             0  eat your veggies: 9 deliciously different recipes   \n",
            "3             1  inclement weather prevents liar from getting t...   \n",
            "4             1  mother comes pretty close to using word 'strea...   \n",
            "5             0                               my white inheritance   \n",
            "6             0         5 ways to file your taxes with less stress   \n",
            "7             1  richard branson's global-warming donation near...   \n",
            "8             1  shadow government getting too large to meet in...   \n",
            "9             0                 lots of parents know this scenario   \n",
            "\n",
            "                                        article_link  \n",
            "0  https://www.theonion.com/thirtysomething-scien...  \n",
            "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
            "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
            "3  https://local.theonion.com/inclement-weather-p...  \n",
            "4  https://www.theonion.com/mother-comes-pretty-c...  \n",
            "5  https://www.huffingtonpost.com/entry/my-white-...  \n",
            "6  https://www.huffingtonpost.com/entry/5-ways-to...  \n",
            "7  https://www.theonion.com/richard-bransons-glob...  \n",
            "8  https://politics.theonion.com/shadow-governmen...  \n",
            "9  https://www.huffingtonpost.comhttp://pubx.co/6...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Processing"
      ],
      "metadata": {
        "id": "pLAfJQ3W-b4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No Pre-Processing at all"
      ],
      "metadata": {
        "id": "DGttj2KWdMsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_headline'] = df['headline']"
      ],
      "metadata": {
        "id": "tfKLOEeKdJeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Pre-Processing"
      ],
      "metadata": {
        "id": "XDhJf42edPtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, action, stopword):\n",
        "  #Lower Caps\n",
        "  #text = text.lower()\n",
        "  #Remove Punctuations\n",
        "  #text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  #https://www.geeksforgeeks.org/text-preprocessing-for-nlp-tasks/\n",
        "    # text = text.lower()  # Lowercase\n",
        "  #text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    #text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "  #text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
        "    # text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
        "  # Tokenize and remove stopwords\n",
        "  words = word_tokenize(text)\n",
        "  if stopword:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "  #If stemming\n",
        "  if action == \"S\":\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "  elif action == \"L\":\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "  return \" \".join(words)\n",
        "\n",
        "# Apply preprocessing to the text column\n",
        "df['clean_headline'] = df['headline'].apply(lambda text: preprocess_text(text, \"\", False))"
      ],
      "metadata": {
        "id": "wsaM8QL_-B56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2NaEqzF4pjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linguistic Features from (feature eng1)"
      ],
      "metadata": {
        "id": "TggX4ptM4tpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos_counts(text):\n",
        "    \"\"\"\n",
        "    Returns a dictionary with counts of certain POS tags (NOUN, VERB, ADJ, ADV)\n",
        "    \"\"\"\n",
        "    pos_tags = pos_tag(word_tokenize(text))\n",
        "    counts = {\n",
        "        'noun_count': 0,\n",
        "        'verb_count': 0,\n",
        "        'adj_count': 0,\n",
        "        'adv_count': 0\n",
        "    }\n",
        "    for word, tag in pos_tags:\n",
        "        if tag.startswith('NN'):\n",
        "            counts['noun_count'] += 1\n",
        "        elif tag.startswith('VB'):\n",
        "            counts['verb_count'] += 1\n",
        "        elif tag.startswith('JJ'):\n",
        "            counts['adj_count'] += 1\n",
        "        elif tag.startswith('RB'):\n",
        "            counts['adv_count'] += 1\n",
        "    return counts\n",
        "\n",
        "def get_text_length(text):\n",
        "    return len(word_tokenize(text))\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_ner_count(text):\n",
        "    doc = nlp(text)\n",
        "    return len(doc.ents)"
      ],
      "metadata": {
        "id": "N845Yq8QriMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['pos_counts'] = df['clean_headline'].apply(get_pos_counts)\n",
        "df['text_length'] = df['clean_headline'].apply(get_text_length)\n",
        "\n",
        "df['noun_count'] = df['pos_counts'].apply(lambda x: x['noun_count'])\n",
        "df['verb_count'] = df['pos_counts'].apply(lambda x: x['verb_count'])\n",
        "df['adj_count'] = df['pos_counts'].apply(lambda x: x['adj_count'])\n",
        "df['adv_count'] = df['pos_counts'].apply(lambda x: x['adv_count'])"
      ],
      "metadata": {
        "id": "txzV71JJs6L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat"
      ],
      "metadata": {
        "id": "uxv6H1LuxZAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ed429f-f28a-4712-bc6b-d60d1c100a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting cmudict (from textstat)\n",
            "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.6.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n",
            "Downloading textstat-0.7.5-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, cmudict, textstat\n",
            "Successfully installed cmudict-1.0.32 pyphen-0.17.2 textstat-0.7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textstat\n",
        "df['flesch_reading_ease'] = df['clean_headline'].apply(lambda text: textstat.flesch_reading_ease(text))\n",
        "df['dale_chall_score'] = df['clean_headline'].apply(lambda text: textstat.dale_chall_readability_score(text))"
      ],
      "metadata": {
        "id": "yxHndzybxYAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "ZecEggrb3G97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9048754-dd36-482b-9eec-94aed39b474a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "df['sentiment_score'] = df['clean_headline'].apply(lambda text: analyzer.polarity_scores(text)['compound'])"
      ],
      "metadata": {
        "id": "ULHVACtS3FgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_chars(text):\n",
        "    return len(text)\n",
        "\n",
        "def count_words(text):\n",
        "    return len(text.split())\n",
        "\n",
        "def count_capital_chars(text):\n",
        "  count=0\n",
        "  for i in text:\n",
        "    if i.isupper():\n",
        "      count+=1\n",
        "  return count\n",
        "\n",
        "def count_capital_words(text):\n",
        "    return sum(map(str.isupper,text.split()))\n",
        "\n",
        "def count_unique_words(text):\n",
        "    return len(set(text.split()))\n",
        "\n",
        "def count_exclamation(text):\n",
        "    return text.count(\"!\")\n",
        "\n",
        "df['char_count'] = df['clean_headline'].apply(count_chars)\n",
        "df['capital_char_count'] = df[\"clean_headline\"].apply(lambda x:count_capital_chars(x))\n",
        "df['capital_word_count'] = df[\"clean_headline\"].apply(lambda x:count_capital_words(x))"
      ],
      "metadata": {
        "id": "XZe3PrZS47co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['stopword_count'] = df['clean_headline'].apply(lambda x: len([word for word in x.split() if word in stopwords.words('english')]))\n",
        "df['word_count'] = df['clean_headline'].apply(count_words)\n",
        "df['stopwords_vs_words'] = df['stopword_count']/df['word_count']"
      ],
      "metadata": {
        "id": "qGPaSCRk5TQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_contrastive_conjunction(text):\n",
        "    contrastive_words = {\"but\", \"although\", \"yet\", \"however\", \"though\"}\n",
        "    return int(any(word in text.split() for word in contrastive_words))\n",
        "\n",
        "df['contrastive_marker'] = df['clean_headline'].apply(has_contrastive_conjunction)"
      ],
      "metadata": {
        "id": "C2rKRYaJ5j7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import textstat\n",
        "import string\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from textblob import TextBlob\n",
        "from scipy.stats import entropy\n",
        "\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "qYbw39fZSasQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47430f6-d102-4d9f-dd96-911c7c932e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "def calculate_entropy(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "    freq_dist = Counter(words)\n",
        "    probs = np.array(list(freq_dist.values())) / sum(freq_dist.values())\n",
        "    return entropy(probs, base=2)  # Shannon Entropy\n",
        "\n",
        "df[\"entropy\"] = df[\"clean_headline\"].apply(calculate_entropy)\n",
        "\n",
        "### 2. **Lexical Diversity (Unique Words / Total Words)**\n",
        "def lexical_diversity(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "    return len(set(words)) / len(words) if len(words) > 0 else 0\n",
        "\n",
        "df[\"lexical_diversity\"] = df[\"clean_headline\"].apply(lexical_diversity)\n",
        "\n",
        "### 6. **Wrong Words (Words Not in WordNet)**\n",
        "def count_wrong_words(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "    return sum(1 for word in words if not wordnet.synsets(word))\n",
        "\n",
        "df[\"wrong_word_count\"] = df[\"clean_headline\"].apply(count_wrong_words)\n",
        "\n",
        "### 7. **Difficult Words (Hard-to-Read Words)**\n",
        "df[\"difficult_word_count\"] = df[\"clean_headline\"].apply(textstat.difficult_words)\n",
        "\n",
        "### 8. **Lengthy Words (Words > 2 Characters)**\n",
        "df[\"lengthy_word_count\"] = df[\"clean_headline\"].apply(lambda words: sum(1 for word in words if len(word) > 2))\n",
        "\n",
        "### 9. **Two-Letter Words**\n",
        "df[\"two_letter_words\"] = df[\"clean_headline\"].apply(lambda words: sum(1 for word in words if len(word) == 2))\n",
        "\n",
        "### 10. **Single-Letter Words**\n",
        "df[\"single_letter_words\"] = df[\"clean_headline\"].apply(lambda words: sum(1 for word in words if len(word) == 1))\n"
      ],
      "metadata": {
        "id": "XYPJRGzAR0yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_incongruity(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_words = 0\n",
        "    neg_words = 0\n",
        "\n",
        "    for word in tokens:\n",
        "        score = analyzer.polarity_scores(word)['compound']\n",
        "        if score >= 0.5:\n",
        "            pos_words += 1\n",
        "        elif score <= -0.5:\n",
        "            neg_words += 1\n",
        "\n",
        "    # Return 1 if both positive and negative words exist → sentiment conflict\n",
        "    return int(pos_words > 0 and neg_words > 0)\n",
        "\n",
        "# Apply to the DataFrame\n",
        "df['sentiment_incongruity'] = df['clean_headline'].apply(detect_incongruity)"
      ],
      "metadata": {
        "id": "zh6xciqX5t3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "None+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "wIhFRiAOAM6G",
        "outputId": "10113567-c450-45f2-dc23-693850422b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-dfd85c18edce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mNone\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Glove"
      ],
      "metadata": {
        "id": "P5Qx2QOvQhUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1HPpXpaVGK1G6W1G5wPZwF9p091qacR8i\n",
        "!unzip \"glove.6B.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmzeQFRDM2C4",
        "outputId": "26d5a94e-2197-4169-cc5f-6385128db608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1HPpXpaVGK1G6W1G5wPZwF9p091qacR8i\n",
            "From (redirected): https://drive.google.com/uc?id=1HPpXpaVGK1G6W1G5wPZwF9p091qacR8i&confirm=t&uuid=9efc0b3b-99ac-446e-9cac-27a33941f0ca\n",
            "To: /content/glove.6B.zip\n",
            "100% 862M/862M [00:24<00:00, 35.7MB/s]\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_glove_embeddings(glove_path):\n",
        "    embeddings = {}\n",
        "    with open(glove_path, 'r', encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            word = parts[0]\n",
        "            vector = np.array(parts[1:], dtype=np.float32)\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_path = \"glove.6B.300d.txt\"  # adjust path if needed\n",
        "glove_dict = load_glove_embeddings(glove_path)\n",
        "\n",
        "# Example: get vector for a word\n",
        "print(glove_dict['amazing'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpt_1L25KrtF",
        "outputId": "3fa4895c-8364-44e5-b7d9-3ab1ea1a1f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.4999e-01  5.3597e-02  9.4669e-02  1.2415e-01 -1.0623e-01  3.2981e-01\n",
            " -3.6563e-02 -4.9109e-01  5.0600e-02 -4.8218e-01  6.9264e-01 -1.5298e-01\n",
            " -2.3069e-01  8.3252e-02  5.6969e-02 -4.4769e-01  2.7878e-01  7.0629e-02\n",
            " -2.8340e-01  4.1989e-01  3.3607e-01  3.3273e-01 -4.2430e-01  1.3433e-01\n",
            "  2.4444e-01  3.6712e-01 -4.7969e-01 -3.8191e-01  1.8654e-01 -1.9120e-01\n",
            " -1.7775e-01 -2.2396e-01 -1.2442e+00 -4.2139e-01 -1.2342e+00  4.5623e-01\n",
            "  1.9550e-02  7.4867e-01  4.7384e-02 -7.7133e-02 -2.6682e-01 -3.6488e-01\n",
            " -2.4977e-02 -6.0338e-02  4.1059e-02  4.3062e-01  2.4870e-01  3.4548e-02\n",
            "  6.1338e-01 -4.3779e-02 -5.3384e-02  4.8766e-01 -4.4736e-02  9.4678e-02\n",
            " -2.7967e-01  7.3181e-01  5.5861e-01  8.9743e-02 -1.2702e-01 -4.8329e-02\n",
            "  1.3241e-01 -2.1868e-01  4.7130e-01  2.3780e-01 -1.1905e-01  1.4091e-01\n",
            "  3.4236e-02  5.8102e-02 -1.0685e-01 -1.2360e-01 -6.4432e-01 -1.2913e-02\n",
            "  5.6400e-02  4.5082e-01 -1.1311e-01 -2.9463e-01 -4.4107e-02 -1.0306e-01\n",
            "  5.9227e-02  8.7667e-02 -6.0326e-01 -1.5421e-01  4.7466e-01  5.4349e-02\n",
            "  9.4245e-02  6.7547e-01  9.3743e-02  3.9292e-02  2.1902e-01 -2.2840e-01\n",
            " -1.1696e-01 -1.9528e-01  5.8218e-02 -3.8343e-01  2.4897e-01 -2.5120e-01\n",
            " -5.1597e-01  4.2212e-02  1.6381e-01 -1.5598e-01  1.7026e-01  4.0956e-01\n",
            "  1.1879e-01 -1.7408e-01  3.9237e-01 -4.9366e-01  1.7514e-01  1.2423e-01\n",
            "  5.7063e-02  2.0705e-01  2.3778e-01  3.2887e-01  5.5798e-02 -1.9037e-01\n",
            "  2.5897e-01 -3.3326e-01  1.4965e-01  2.3986e-01 -1.3822e-01  2.7421e-01\n",
            "  1.7235e-01 -2.9496e-01  2.7371e-03  8.5009e-02  2.4704e-01 -2.4956e-01\n",
            " -1.1558e-02  5.6495e-01 -3.7383e-01  2.8987e-01 -2.1087e-01 -5.7253e-02\n",
            " -1.2836e-01  9.3511e-02 -7.9462e-01  2.0676e-02 -1.8020e-01 -3.4054e-04\n",
            " -2.5556e-01  7.0471e-01 -4.2855e-01  7.6964e-02 -2.3587e-01  1.0920e-01\n",
            "  2.3406e-02  1.3370e-01 -5.9503e-01  1.5626e-01 -2.1945e-01  4.8405e-02\n",
            " -6.2798e-01 -4.6496e-01 -1.1485e-01 -7.3404e-01  6.0442e-01 -2.2954e-01\n",
            " -1.5352e-01  2.3170e-01 -1.9323e-01 -3.4891e-01  1.0769e-01 -3.2297e-01\n",
            "  4.4082e-01  1.6618e-01 -3.9881e-01  2.0095e-01 -2.7796e-01  1.5464e-01\n",
            " -1.0777e-01 -2.4873e-02  1.4706e-01 -5.2247e-01 -3.5819e-01 -4.4224e-02\n",
            " -4.7287e-02  1.7179e-01 -3.2419e-01 -1.5742e-01  1.0100e-02  8.4755e-02\n",
            " -2.7929e-01 -4.3222e-01  7.0830e-01 -2.1706e-01  1.6192e-01  5.8348e-03\n",
            "  4.3244e-01 -2.1973e-01 -4.5149e-02  6.0086e-01 -3.4385e-01  5.2345e-02\n",
            "  3.0757e-01  8.8022e-02 -2.9415e-01  3.1277e-03 -4.7851e-01  2.1288e-01\n",
            " -4.9584e-01 -1.0055e-01  1.4569e+00  4.2731e-02 -6.8303e-02  1.4197e-01\n",
            " -3.4525e-01  2.7788e-01 -2.0811e-02  4.4559e-01 -1.9598e-01 -4.4542e-01\n",
            " -5.8920e-01 -1.6964e-01  1.0168e-01 -6.2910e-01  3.4323e-01 -3.0170e-01\n",
            " -5.3384e-01 -3.9779e-02  1.8163e-02 -4.8881e-02 -2.0804e-01 -1.9576e-01\n",
            " -3.1244e-01  7.4901e-02 -3.2654e-02 -1.2901e-01  2.1407e-01 -1.9287e-01\n",
            " -3.2234e-01 -1.3269e-01 -4.0424e-01  6.5655e-02 -1.0051e-01 -8.6236e-01\n",
            " -2.8633e-01  3.5023e-01  1.0131e-01 -1.3971e-01 -2.7010e-01 -9.5299e-03\n",
            "  6.2880e-01 -5.4393e-02 -5.5348e-01  7.5561e-01 -3.2622e-01 -3.9326e-02\n",
            " -3.7252e-01  2.7311e-01  2.2658e-01 -1.5553e-01  2.3109e-01 -7.8274e-01\n",
            " -2.1581e-01 -4.1757e-01  3.3484e-01 -8.8353e-02 -8.5984e-02 -2.1289e-01\n",
            " -3.7182e-01 -3.1643e-01  2.1288e-01 -3.6237e-02 -9.2752e-02  6.6673e-03\n",
            "  2.4336e-01  2.0090e-01 -3.9357e-01 -8.8579e-02  4.3742e-02 -1.2053e-01\n",
            " -2.6795e-01 -2.5263e-01  5.1712e-02 -5.7308e-02  3.7963e-01  6.7176e-02\n",
            " -7.4044e-01  5.1321e-02 -9.9559e-02 -1.1743e-01 -6.3087e-02  2.9985e-02\n",
            "  1.8439e-01  5.3850e-03 -1.4725e-01 -4.1222e-01 -6.7534e-01  3.5182e-01\n",
            " -1.1665e-01  1.0121e-01 -2.8311e-01  4.4419e-03 -5.0686e-01  3.2047e-01\n",
            " -3.5880e-03 -2.8969e-01  8.2759e-02  3.0646e-01  6.6816e-02 -2.5007e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_to_glove_vector(sentence, glove_dict, dim=300):\n",
        "    words = sentence.lower().split()\n",
        "    vectors = [glove_dict[word] for word in words if word in glove_dict]\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(dim)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "df['word_embedding'] = df['clean_headline'].apply(\n",
        "    lambda x: sentence_to_glove_vector(x, glove_dict, dim=300)\n",
        ")"
      ],
      "metadata": {
        "id": "HRqdYVXpKwTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf-idf"
      ],
      "metadata": {
        "id": "XxRzIp-kA6D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_glove = np.vstack(df['word_embedding'].values)\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_glove, X_ling])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_tfidf])\n",
        "X_test_combined = hstack([X_test_tfidf])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "ocyyNDGMA7Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf-idf + Ling"
      ],
      "metadata": {
        "id": "b3eItOu6_9bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_glove = np.vstack(df['word_embedding'].values)\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_ling])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "7ZKeqzKL__Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glove + tf-idf + Linguistic"
      ],
      "metadata": {
        "id": "r0uTWa2485zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_glove = np.vstack(df['word_embedding'].values)\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_glove, X_ling])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "bI91BcGT891e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glove + tf-idf"
      ],
      "metadata": {
        "id": "KgmMswbW-Eoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_glove = np.vstack(df['word_embedding'].values)\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_glove])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "cLecsw5N-GPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glove + Ling"
      ],
      "metadata": {
        "id": "-gBncVsq-NXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_glove = np.vstack(df['word_embedding'].values)\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_glove, X_ling])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_sparse])\n",
        "X_test_combined = hstack([X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "r-IB9RD5-TQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glove"
      ],
      "metadata": {
        "id": "EIVPp6_KBKMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_glove = np.vstack(df['word_embedding'].values)\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_glove])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_sparse])\n",
        "X_test_combined = hstack([X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "5bUPIjCbBKqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linguistics"
      ],
      "metadata": {
        "id": "xY4IQwJKBgui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_glove = np.vstack(df['word_embedding'].values)\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_ling])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_sparse])\n",
        "X_test_combined = hstack([X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "bgIohfnGBMrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hQMWUAR6Biwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sBERT sentence transfomer"
      ],
      "metadata": {
        "id": "75hIHSZ5FbCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentence-transformers\n"
      ],
      "metadata": {
        "id": "2N8dZsWmFaad",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637c098f-43aa-4166-c29a-93d9b207809c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "bert_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "7znVHpeRFcoi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "cad14006cd514a289dcc3135a51b6a26",
            "4aab01c8f0a34b6c93d586e4116f4bb8",
            "418f132b14cd47f98eae040ba4d054bb",
            "2a1811848e8e4cb5b803c1e15da44907",
            "6ce08dc11765447abeb8ebe563a17f41",
            "9eda00822e9944edab5dd06a51e81e16",
            "e0ac2313484c4acf93e75a44ebaf6134",
            "6f0f53f89d4a40a8948169405ca9c6e6",
            "df816b1556a84118aef4cbe6706fa1be",
            "461fd2554de7410089831f69d0f8023d",
            "03b85a046cf84a4d9f61cbe3c1875ce9",
            "1972665de4a949aa8bd09ec8aeca2f73",
            "378a789b98974f6e930792ad2ab3d634",
            "b5eb882ecd50483eb9a2e66b68336e31",
            "b86603efbb6443d5ad0a0744cf7d1e70",
            "c7d822bcec1c4340bafb5fc9a349946e",
            "3915cf537b2c441bacef6e439f96e232",
            "4c5aba9f03684531b1545d5b358a1861",
            "cd9b6f42deed439ea730e0dabce66e08",
            "9a5b1e3e83424f3aabc756d270ebc4de",
            "3c1e222d6b4c47079c3a23335fdedc88",
            "d33a4dd26ade49f5bee8588dffebad5e",
            "9a778c07ec3d479aa350022790a27655",
            "11419f3ea2364628a9c897caf64ee7e4",
            "4a5c23b2e860467fa66db9485c7fbf3b",
            "3eb804c3ad184d3dbe5f7b68f625b289",
            "fb8b3904ed7341f08d0f77d3d0f4d9ad",
            "e46515fff2a24d2bb1d0fb0aedab35c2",
            "de4348b1002e451f869265189115c1f0",
            "a2bf9fb77a7d4e55ba00ff7bdb00291f",
            "eb3e15ffed9246439ca7d9ec92a542b6",
            "aca9bf2d2a6b43ef8749eb5128f6a788",
            "6d8daf27c149425eaeefff70d3054818",
            "b2b8e8dcf4b94ea18f00b66dd7acfb0c",
            "aa0ae1d21a4b4752bb488815643ab731",
            "a8b8c63018bd494c956ac991c5d6c1e0",
            "9814726fd9d343a0a24698cd6991aaf6",
            "268bec17b17d4d7f8a110e49410286b2",
            "9394f4bade7d407c91ae23cb3799cde4",
            "2f04b22a4939484a9bb81c65b3be75c4",
            "107b13cfd92442b9872eed3517e90ec2",
            "9f32bc93e13944779f7ec74774858c76",
            "467f0f5845cb45f89265c9f1c7ac9125",
            "23db974d2d764fe49983d8cbbba1484c",
            "6bca75e8201e4592a7853c81a247aeba",
            "100eb6a2479d4ff49de01219a6968401",
            "19d261d95307430c9b70b40a9532f417",
            "1ae5d1b976424ff988bf16ec881a14a5",
            "6b2f7d37644940bfb1848e56585e9108",
            "5ebbaa0775124cf581f7ae55b534aedb",
            "8e9e349aa6c645f685c5102115649b97",
            "8ddf0838a9bd4ab084f37a867d0e8e64",
            "854fc13539464310be80cef7c3b20888",
            "bf102a3056cc47ae9795c5a686fd1832",
            "f692f95196f043068d72e7754f16af8b",
            "d82e560f77ce403eace722a20f79f6a9",
            "09c52462dc4e4fd09381cd9b75203868",
            "5b8973e4a3fe441a9d052fd5e35c3600",
            "561d21158c7749b4b24e1e84e9af6ea8",
            "b236ab38d4ab4eaebce72887703bb813",
            "51cbe97ee1864c29882fcaa88a7bd609",
            "29c2f438295744198f52afedd92e17ae",
            "f339655108d4434fb37d13dddc9b59c5",
            "230f6909ee894e9cbd63b0adbb26baa3",
            "f700521f34c94cf08eefa19cc2664ecb",
            "c871038d3fe646aa97b231004e9837cc",
            "3d55ecd9a64948ccbf23da53b35efc55",
            "5e74d1466c4d4b10b89eb9918eb38e71",
            "95ea0f67cf1b4c279957c94acfacee9b",
            "4b786e050f924155912a85761715e694",
            "562b982daf0647bca672ae0078257dd1",
            "5e2b13e0955349fb8d979ccdabc34a8b",
            "6b49e926704747dca5b808d02d7de323",
            "344f918f565e4ccaa7d915e5be6c36fa",
            "210e8366398246528324d1f25794bec1",
            "117fda74f52841eb88ef555b55e97a07",
            "d876f26225d643eaaeeb6e3df897cd53",
            "fadc5dba21eb4f01b8fb9923166ceda2",
            "f71cc13abc684cd3b1b9daf160b82673",
            "094f8e1db0a04bdc93f18bcbcb8d19f0",
            "fbfd65ad2aae4b1f896fd9d60326b91b",
            "f17b8079637344458aad58f9fe1d7ead",
            "cf4a6cb495644f58966550296812e605",
            "bdb4995871854619a663eea4c86bd931",
            "0678408929d74ab18a9a5e38eb65b428",
            "d44b0e64a08b43129cee2119efe269b7",
            "2518bae691604051bab0864a06381223",
            "1c6609d9c9f149f7b69e014429546fc0",
            "576010c2d36f474c9a80ef7851b81005",
            "ad83b26edad6469fa4331395a15bb05d",
            "124403f555e5422589751b4841032b43",
            "8bd225f101a14838b1a09bf9099c56b9",
            "2fe665d0c19f49cdbc9fb2345f3e19c2",
            "a343807fa1c84a81969b2f43e10be549",
            "ab08c374eaa94c0cb046ab53af42e216",
            "f98bfb454f6b4d0e8554c0f87d0e9957",
            "814294427099459fbd4fda7069b840f6",
            "0d73000b0ea14f249978503565f5dd7e",
            "c9bc327bcb88414383ca0e9a28159a80",
            "688508faea374efbba117fb23e008101",
            "c427fa30d5dd43a6a246119dcae6ba05",
            "d02f3501385d45bd923edace2fa76d49",
            "82096db1e5394355af58faafc6084cad",
            "6bb12ce392924a308c4d80754b38613a",
            "59eee6297aae4da1a6a89d30178397a8",
            "0c842c525fd74615930889e5693ddaba",
            "e4014ae1cc544f1d81e272621539db92",
            "acf8de62aaf34b2592ce03381c167e4d",
            "f16f42e83210404986087217a856cf15",
            "7f9c1d00e2d64c328cb8d14118889719",
            "0e23e54f44e84c36901f0a36609d2465",
            "bafa72428a1843b98530c0382703eaf4",
            "a0186e4b8b1847bca3d04b590bac9dab",
            "7a5d69b21cad4708aec6d63ed1d50ffd",
            "e20c3b1742c94cd2b77171b03de23b3b",
            "3de5f77e93d043339e360db225b40297",
            "16b0d416d084466cbd9bcf07634788c8",
            "a3f348828be7472b90a54771faabaacc",
            "a9872da3013946c99988de4b907c2d01",
            "6c9f10392b344d97abc35f4586296518",
            "5b7efca6b0a04a1fb8633771ab3354eb"
          ]
        },
        "outputId": "33f9a6d0-0b57-40be-e3ad-f3fe525e479c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cad14006cd514a289dcc3135a51b6a26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1972665de4a949aa8bd09ec8aeca2f73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a778c07ec3d479aa350022790a27655"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2b8e8dcf4b94ea18f00b66dd7acfb0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bca75e8201e4592a7853c81a247aeba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d82e560f77ce403eace722a20f79f6a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d55ecd9a64948ccbf23da53b35efc55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fadc5dba21eb4f01b8fb9923166ceda2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "576010c2d36f474c9a80ef7851b81005"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "688508faea374efbba117fb23e008101"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e23e54f44e84c36901f0a36609d2465"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sBERT + tf-idf + Ling"
      ],
      "metadata": {
        "id": "uw9JGGO-Pdvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_bert = bert_model.encode(df['clean_headline'].tolist(), show_progress_bar=True)\n",
        "print(\"BERT embeddings shape:\", X_bert.shape)\n",
        "\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_bert, X_ling])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "mEkCa3UmFmgG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "1e3968cd4d0a4a45825f7a18a5e34b13",
            "6babec2f2f7d4a2a864b9ac96b23d843",
            "60b9e433e0a84f5d977609eaff8d3e6f",
            "be2b235b095148ea89d3fb34806c228a",
            "51e7e443f948483393d7c939bc8389f7",
            "45938eb951fb44a89eba292dc438f41e",
            "1d96de751ca6403dbc17d2f6b53d1343",
            "e14ebbf77743417eb8b37038585c71da",
            "f04f459789c14d89ac7b90eb8ba3803a",
            "473edfc33c434d76962084c264136a87",
            "e985c186efd6409e903177bff7483fba"
          ]
        },
        "outputId": "5ed2fecd-9558-4455-f3d6-dbfe8af39f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/895 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e3968cd4d0a4a45825f7a18a5e34b13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT embeddings shape: (28619, 384)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87      3746\n",
            "           1       0.86      0.85      0.85      3409\n",
            "\n",
            "    accuracy                           0.86      7155\n",
            "   macro avg       0.86      0.86      0.86      7155\n",
            "weighted avg       0.86      0.86      0.86      7155\n",
            "\n",
            "[[3263  483]\n",
            " [ 504 2905]]\n",
            "0.8617082947059289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sBERT + Ling"
      ],
      "metadata": {
        "id": "effM6l5dPxIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "print(\"BERT embeddings shape:\", X_bert.shape)\n",
        "\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_bert, X_ling])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_sparse])\n",
        "X_test_combined = hstack([X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "yIM0k9ZEPxIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sBERT + tf-idf"
      ],
      "metadata": {
        "id": "1fkMVk86P2Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "print(\"BERT embeddings shape:\", X_bert.shape)\n",
        "\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_bert])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "UOz_3pBOP2Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_combined.shape)"
      ],
      "metadata": {
        "id": "rPspGUtVVD9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sBERT Only"
      ],
      "metadata": {
        "id": "rfV386Ndk_Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "print(\"BERT embeddings shape:\", X_bert.shape)\n",
        "\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_bert])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([ X_train_sparse])\n",
        "X_test_combined = hstack([X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYWMgpSJk-P3",
        "outputId": "45c6bcd0-8618-4e21-a4c7-9f00c6941541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT embeddings shape: (28619, 384)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81      3746\n",
            "           1       0.79      0.79      0.79      3409\n",
            "\n",
            "    accuracy                           0.80      7155\n",
            "   macro avg       0.80      0.80      0.80      7155\n",
            "weighted avg       0.80      0.80      0.80      7155\n",
            "\n",
            "[[3025  721]\n",
            " [ 723 2686]]\n",
            "0.7977290282930569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using BERT CLS"
      ],
      "metadata": {
        "id": "FyZBfNt4vG2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Not Fine Tuned"
      ],
      "metadata": {
        "id": "JKWWHGkIxjVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel # Use AutoModel for hidden states\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "# --- Configuration ---\n",
        "BERT_MODEL_NAME = 'bert-base-uncased'\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 32\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "df['is_sarcastic'] = df['is_sarcastic'].astype(int)\n",
        "df['clean_headline'] = df['clean_headline'].astype(str)\n",
        "\n",
        "print(f\"Loading tokenizer and model: {BERT_MODEL_NAME}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
        "bert_model = AutoModel.from_pretrained(BERT_MODEL_NAME)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model.to(device)\n",
        "bert_model.eval()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "def get_bert_cls_embeddings(texts, model, tokenizer, device, max_length, batch_size):\n",
        "    \"\"\"Generates [CLS] token embeddings for a list of texts.\"\"\"\n",
        "    all_cls_embeddings = []\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Generating embeddings in batches of {batch_size}...\")\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Extract the hidden state of the [CLS] token (first token) from the last layer\n",
        "        # last_hidden_state shape: (batch_size, sequence_length, hidden_size)\n",
        "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        all_cls_embeddings.append(cls_embeddings.cpu().numpy())\n",
        "\n",
        "        if (i // batch_size + 1) % 50 == 0: # Print progress every 50 batches\n",
        "             print(f\"  Processed batch {i // batch_size + 1}/{len(texts) // batch_size + 1}\")\n",
        "\n",
        "    print(\"Finished generating embeddings.\")\n",
        "    # Combine embeddings from all batches\n",
        "    return np.vstack(all_cls_embeddings)\n",
        "\n",
        "print(\"Generating BERT [CLS] embeddings...\")\n",
        "X_bert = get_bert_cls_embeddings(\n",
        "    df['clean_headline'].tolist(),\n",
        "    bert_model,\n",
        "    tokenizer,\n",
        "    device,\n",
        "    MAX_LENGTH,\n",
        "    BATCH_SIZE\n",
        ")\n",
        "print(\"BERT [CLS] embeddings shape:\", X_bert.shape) # Shape: (num_samples, 768 for bert-base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgIX8iUAvKjo",
        "outputId": "6a802005-9ca7-41d7-e30a-620b40d4b6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer and model: bert-base-uncased\n",
            "Using device: cuda\n",
            "Generating BERT [CLS] embeddings...\n",
            "Generating embeddings in batches of 32...\n",
            "  Processed batch 50/895\n",
            "  Processed batch 100/895\n",
            "  Processed batch 150/895\n",
            "  Processed batch 200/895\n",
            "  Processed batch 250/895\n",
            "  Processed batch 300/895\n",
            "  Processed batch 350/895\n",
            "  Processed batch 400/895\n",
            "  Processed batch 450/895\n",
            "  Processed batch 500/895\n",
            "  Processed batch 550/895\n",
            "  Processed batch 600/895\n",
            "  Processed batch 650/895\n",
            "  Processed batch 700/895\n",
            "  Processed batch 750/895\n",
            "  Processed batch 800/895\n",
            "  Processed batch 850/895\n",
            "Finished generating embeddings.\n",
            "BERT [CLS] embeddings shape: (28619, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT CLS + Ling + tf-idf"
      ],
      "metadata": {
        "id": "p541Fx1almMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Linguistic Features\n",
        "print(\"Extracting linguistic features...\")\n",
        "ling_feature_names = ['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "                      'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "                      'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "                      'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']\n",
        "X_ling = df[ling_feature_names].values\n",
        "print(\"Linguistic features shape:\", X_ling.shape)\n",
        "\n",
        "# 3. Combine BERT [CLS] + Linguistic Features (Dense)\n",
        "print(\"Combining BERT [CLS] and linguistic features...\")\n",
        "X_gling = np.hstack([X_bert, X_ling])\n",
        "print(\"Combined BERT+Ling shape:\", X_gling.shape)\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "# --- Train/Test Split ---\n",
        "print(\"Splitting data into train/test sets...\")\n",
        "# Split the combined dense features and labels, keep track of original indices\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42 # Explicit test_size\n",
        ")\n",
        "print(f\"Train features shape: {X_train_gling.shape}, Test features shape: {X_test_gling.shape}\")\n",
        "\n",
        "# --- Feature Scaling ---\n",
        "print(\"Scaling combined BERT+Ling features...\")\n",
        "# Scale the combined BERT+Ling features (fit on train, transform both)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "# Convert scaled features to sparse format (optional, but hstack prefers it)\n",
        "X_train_sparse_scaled = csr_matrix(X_train_scaled)\n",
        "X_test_sparse_scaled = csr_matrix(X_test_scaled)\n",
        "print(\"Scaled features shape (sparse):\", X_train_sparse_scaled.shape)\n",
        "\n",
        "# --- TF-IDF Features ---\n",
        "print(\"Generating TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer() # Optional: limit TF-IDF features\n",
        "\n",
        "# Fit TF-IDF on the training text data using the train indices\n",
        "X_train_tfidf = tfidf.fit_transform(df.loc[idx_train, 'clean_headline'])\n",
        "# Transform the test text data using the fitted TF-IDF vectorizer and test indices\n",
        "X_test_tfidf = tfidf.transform(df.loc[idx_test, 'clean_headline'])\n",
        "print(\"TF-IDF Train shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# --- Final Feature Combination ---\n",
        "print(\"Combining TF-IDF and Scaled (BERT+Ling) features...\")\n",
        "# Combine TF-IDF + Scaled(BERT+Ling) features using hstack\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse_scaled])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse_scaled])\n",
        "print(\"Final Combined Train shape:\", X_train_combined.shape)\n",
        "print(\"Final Combined Test shape:\", X_test_combined.shape)\n",
        "\n",
        "# --- Logistic Regression Model ---\n",
        "print(\"\\nTraining Logistic Regression model...\")\n",
        "# Use a solver suitable for potentially large sparse data like liblinear or saga\n",
        "lr = LogisticRegression(class_weight='balanced',max_iter=10000, random_state=42)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "print(\"\\nEvaluating Logistic Regression model...\")\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "# Use zero_division=0 to handle cases where a class might have no predictions in a batch/split\n",
        "print(classification_report(Y_test, y_pred, zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(Y_test, y_pred, labels=lr.classes_)\n",
        "print(cm)\n",
        "\n",
        "print(f\"\\nMacro F1 Score: {f1_score(Y_test, y_pred, average='macro', zero_division=0):.4f}\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGO4DCiAllUV",
        "outputId": "aae91cc5-d22a-4428-cbb2-62900d07f62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting linguistic features...\n",
            "Linguistic features shape: (28619, 17)\n",
            "Combining BERT [CLS] and linguistic features...\n",
            "Combined BERT+Ling shape: (28619, 785)\n",
            "Splitting data into train/test sets...\n",
            "Train features shape: (21464, 785), Test features shape: (7155, 785)\n",
            "Scaling combined BERT+Ling features...\n",
            "Scaled features shape (sparse): (21464, 785)\n",
            "Generating TF-IDF features...\n",
            "TF-IDF Train shape: (21464, 23183)\n",
            "TF-IDF Test shape: (7155, 23183)\n",
            "Combining TF-IDF and Scaled (BERT+Ling) features...\n",
            "Final Combined Train shape: (21464, 23968)\n",
            "Final Combined Test shape: (7155, 23968)\n",
            "\n",
            "Training Logistic Regression model...\n",
            "\n",
            "Evaluating Logistic Regression model...\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90      3746\n",
            "           1       0.88      0.88      0.88      3409\n",
            "\n",
            "    accuracy                           0.89      7155\n",
            "   macro avg       0.89      0.89      0.89      7155\n",
            "weighted avg       0.89      0.89      0.89      7155\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3353  393]\n",
            " [ 393 3016]]\n",
            "\n",
            "Macro F1 Score: 0.8899\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT CLS only"
      ],
      "metadata": {
        "id": "EU3MgpJVmpkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Linguistic Features\n",
        "print(\"Extracting linguistic features...\")\n",
        "ling_feature_names = ['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "                      'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "                      'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "                      'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']\n",
        "X_ling = df[ling_feature_names].values\n",
        "print(\"Linguistic features shape:\", X_ling.shape)\n",
        "\n",
        "# 3. Combine BERT [CLS] + Linguistic Features (Dense)\n",
        "print(\"Combining BERT [CLS] and linguistic features...\")\n",
        "X_gling = np.hstack([X_bert])\n",
        "print(\"Combined BERT+Ling shape:\", X_gling.shape)\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "# --- Train/Test Split ---\n",
        "print(\"Splitting data into train/test sets...\")\n",
        "# Split the combined dense features and labels, keep track of original indices\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42 # Explicit test_size\n",
        ")\n",
        "print(f\"Train features shape: {X_train_gling.shape}, Test features shape: {X_test_gling.shape}\")\n",
        "\n",
        "# --- Feature Scaling ---\n",
        "print(\"Scaling combined BERT+Ling features...\")\n",
        "# Scale the combined BERT+Ling features (fit on train, transform both)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "# Convert scaled features to sparse format (optional, but hstack prefers it)\n",
        "X_train_sparse_scaled = csr_matrix(X_train_scaled)\n",
        "X_test_sparse_scaled = csr_matrix(X_test_scaled)\n",
        "print(\"Scaled features shape (sparse):\", X_train_sparse_scaled.shape)\n",
        "\n",
        "# --- TF-IDF Features ---\n",
        "print(\"Generating TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer() # Optional: limit TF-IDF features\n",
        "\n",
        "# Fit TF-IDF on the training text data using the train indices\n",
        "X_train_tfidf = tfidf.fit_transform(df.loc[idx_train, 'clean_headline'])\n",
        "# Transform the test text data using the fitted TF-IDF vectorizer and test indices\n",
        "X_test_tfidf = tfidf.transform(df.loc[idx_test, 'clean_headline'])\n",
        "print(\"TF-IDF Train shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# --- Final Feature Combination ---\n",
        "print(\"Combining TF-IDF and Scaled (BERT+Ling) features...\")\n",
        "# Combine TF-IDF + Scaled(BERT+Ling) features using hstack\n",
        "X_train_combined = hstack([ X_train_sparse_scaled])\n",
        "X_test_combined = hstack([X_test_sparse_scaled])\n",
        "print(\"Final Combined Train shape:\", X_train_combined.shape)\n",
        "print(\"Final Combined Test shape:\", X_test_combined.shape)\n",
        "\n",
        "# --- Logistic Regression Model ---\n",
        "print(\"\\nTraining Logistic Regression model...\")\n",
        "# Use a solver suitable for potentially large sparse data like liblinear or saga\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=42)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "print(\"\\nEvaluating Logistic Regression model...\")\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "# Use zero_division=0 to handle cases where a class might have no predictions in a batch/split\n",
        "print(classification_report(Y_test, y_pred, zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(Y_test, y_pred, labels=lr.classes_)\n",
        "print(cm)\n",
        "\n",
        "print(f\"\\nMacro F1 Score: {f1_score(Y_test, y_pred, average='macro', zero_division=0):.4f}\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WODPgzOjmpku",
        "outputId": "17d8a72f-37de-4089-d16a-5100fd046c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting linguistic features...\n",
            "Linguistic features shape: (28619, 17)\n",
            "Combining BERT [CLS] and linguistic features...\n",
            "Combined BERT+Ling shape: (28619, 768)\n",
            "Splitting data into train/test sets...\n",
            "Train features shape: (21464, 768), Test features shape: (7155, 768)\n",
            "Scaling combined BERT+Ling features...\n",
            "Scaled features shape (sparse): (21464, 768)\n",
            "Generating TF-IDF features...\n",
            "TF-IDF Train shape: (21464, 23183)\n",
            "TF-IDF Test shape: (7155, 23183)\n",
            "Combining TF-IDF and Scaled (BERT+Ling) features...\n",
            "Final Combined Train shape: (21464, 768)\n",
            "Final Combined Test shape: (7155, 768)\n",
            "\n",
            "Training Logistic Regression model...\n",
            "\n",
            "Evaluating Logistic Regression model...\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.86      3746\n",
            "           1       0.85      0.85      0.85      3409\n",
            "\n",
            "    accuracy                           0.86      7155\n",
            "   macro avg       0.86      0.86      0.86      7155\n",
            "weighted avg       0.86      0.86      0.86      7155\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3230  516]\n",
            " [ 502 2907]]\n",
            "\n",
            "Macro F1 Score: 0.8574\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT CLS + Ling"
      ],
      "metadata": {
        "id": "jMR1fS63mwi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Linguistic Features\n",
        "print(\"Extracting linguistic features...\")\n",
        "ling_feature_names = ['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "                      'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "                      'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "                      'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']\n",
        "X_ling = df[ling_feature_names].values\n",
        "print(\"Linguistic features shape:\", X_ling.shape)\n",
        "\n",
        "# 3. Combine BERT [CLS] + Linguistic Features (Dense)\n",
        "print(\"Combining BERT [CLS] and linguistic features...\")\n",
        "X_gling = np.hstack([X_bert, X_ling])\n",
        "print(\"Combined BERT+Ling shape:\", X_gling.shape)\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "# --- Train/Test Split ---\n",
        "print(\"Splitting data into train/test sets...\")\n",
        "# Split the combined dense features and labels, keep track of original indices\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42 # Explicit test_size\n",
        ")\n",
        "print(f\"Train features shape: {X_train_gling.shape}, Test features shape: {X_test_gling.shape}\")\n",
        "\n",
        "# --- Feature Scaling ---\n",
        "print(\"Scaling combined BERT+Ling features...\")\n",
        "# Scale the combined BERT+Ling features (fit on train, transform both)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "# Convert scaled features to sparse format (optional, but hstack prefers it)\n",
        "X_train_sparse_scaled = csr_matrix(X_train_scaled)\n",
        "X_test_sparse_scaled = csr_matrix(X_test_scaled)\n",
        "print(\"Scaled features shape (sparse):\", X_train_sparse_scaled.shape)\n",
        "\n",
        "# --- TF-IDF Features ---\n",
        "print(\"Generating TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer() # Optional: limit TF-IDF features\n",
        "\n",
        "# Fit TF-IDF on the training text data using the train indices\n",
        "X_train_tfidf = tfidf.fit_transform(df.loc[idx_train, 'clean_headline'])\n",
        "# Transform the test text data using the fitted TF-IDF vectorizer and test indices\n",
        "X_test_tfidf = tfidf.transform(df.loc[idx_test, 'clean_headline'])\n",
        "print(\"TF-IDF Train shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# --- Final Feature Combination ---\n",
        "print(\"Combining TF-IDF and Scaled (BERT+Ling) features...\")\n",
        "# Combine TF-IDF + Scaled(BERT+Ling) features using hstack\n",
        "X_train_combined = hstack([ X_train_sparse_scaled])\n",
        "X_test_combined = hstack([ X_test_sparse_scaled])\n",
        "print(\"Final Combined Train shape:\", X_train_combined.shape)\n",
        "print(\"Final Combined Test shape:\", X_test_combined.shape)\n",
        "\n",
        "# --- Logistic Regression Model ---\n",
        "print(\"\\nTraining Logistic Regression model...\")\n",
        "# Use a solver suitable for potentially large sparse data like liblinear or saga\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=42)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "print(\"\\nEvaluating Logistic Regression model...\")\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "# Use zero_division=0 to handle cases where a class might have no predictions in a batch/split\n",
        "print(classification_report(Y_test, y_pred, zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(Y_test, y_pred, labels=lr.classes_)\n",
        "print(cm)\n",
        "\n",
        "print(f\"\\nMacro F1 Score: {f1_score(Y_test, y_pred, average='macro', zero_division=0):.4f}\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvLzkgV-mwi4",
        "outputId": "e14d0305-24d5-42cc-99c4-326a975501ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting linguistic features...\n",
            "Linguistic features shape: (28619, 17)\n",
            "Combining BERT [CLS] and linguistic features...\n",
            "Combined BERT+Ling shape: (28619, 785)\n",
            "Splitting data into train/test sets...\n",
            "Train features shape: (21464, 785), Test features shape: (7155, 785)\n",
            "Scaling combined BERT+Ling features...\n",
            "Scaled features shape (sparse): (21464, 785)\n",
            "Generating TF-IDF features...\n",
            "TF-IDF Train shape: (21464, 23183)\n",
            "TF-IDF Test shape: (7155, 23183)\n",
            "Combining TF-IDF and Scaled (BERT+Ling) features...\n",
            "Final Combined Train shape: (21464, 785)\n",
            "Final Combined Test shape: (7155, 785)\n",
            "\n",
            "Training Logistic Regression model...\n",
            "\n",
            "Evaluating Logistic Regression model...\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87      3746\n",
            "           1       0.86      0.86      0.86      3409\n",
            "\n",
            "    accuracy                           0.87      7155\n",
            "   macro avg       0.87      0.87      0.87      7155\n",
            "weighted avg       0.87      0.87      0.87      7155\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3258  488]\n",
            " [ 471 2938]]\n",
            "\n",
            "Macro F1 Score: 0.8657\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT CLS + tf-idf"
      ],
      "metadata": {
        "id": "hgSd-_zJm9wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Linguistic Features\n",
        "print(\"Extracting linguistic features...\")\n",
        "ling_feature_names = ['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "                      'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "                      'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "                      'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']\n",
        "X_ling = df[ling_feature_names].values\n",
        "print(\"Linguistic features shape:\", X_ling.shape)\n",
        "\n",
        "# 3. Combine BERT [CLS] + Linguistic Features (Dense)\n",
        "print(\"Combining BERT [CLS] and linguistic features...\")\n",
        "X_gling = np.hstack([X_bert])\n",
        "print(\"Combined BERT+Ling shape:\", X_gling.shape)\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "# --- Train/Test Split ---\n",
        "print(\"Splitting data into train/test sets...\")\n",
        "# Split the combined dense features and labels, keep track of original indices\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42 # Explicit test_size\n",
        ")\n",
        "print(f\"Train features shape: {X_train_gling.shape}, Test features shape: {X_test_gling.shape}\")\n",
        "\n",
        "# --- Feature Scaling ---\n",
        "print(\"Scaling combined BERT+Ling features...\")\n",
        "# Scale the combined BERT+Ling features (fit on train, transform both)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "# Convert scaled features to sparse format (optional, but hstack prefers it)\n",
        "X_train_sparse_scaled = csr_matrix(X_train_scaled)\n",
        "X_test_sparse_scaled = csr_matrix(X_test_scaled)\n",
        "print(\"Scaled features shape (sparse):\", X_train_sparse_scaled.shape)\n",
        "\n",
        "# --- TF-IDF Features ---\n",
        "print(\"Generating TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer() # Optional: limit TF-IDF features\n",
        "\n",
        "# Fit TF-IDF on the training text data using the train indices\n",
        "X_train_tfidf = tfidf.fit_transform(df.loc[idx_train, 'clean_headline'])\n",
        "# Transform the test text data using the fitted TF-IDF vectorizer and test indices\n",
        "X_test_tfidf = tfidf.transform(df.loc[idx_test, 'clean_headline'])\n",
        "print(\"TF-IDF Train shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# --- Final Feature Combination ---\n",
        "print(\"Combining TF-IDF and Scaled (BERT+Ling) features...\")\n",
        "# Combine TF-IDF + Scaled(BERT+Ling) features using hstack\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse_scaled])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse_scaled])\n",
        "print(\"Final Combined Train shape:\", X_train_combined.shape)\n",
        "print(\"Final Combined Test shape:\", X_test_combined.shape)\n",
        "\n",
        "# --- Logistic Regression Model ---\n",
        "print(\"\\nTraining Logistic Regression model...\")\n",
        "# Use a solver suitable for potentially large sparse data like liblinear or saga\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=42)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "print(\"\\nEvaluating Logistic Regression model...\")\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "# Use zero_division=0 to handle cases where a class might have no predictions in a batch/split\n",
        "print(classification_report(Y_test, y_pred, zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(Y_test, y_pred, labels=lr.classes_)\n",
        "print(cm)\n",
        "\n",
        "print(f\"\\nMacro F1 Score: {f1_score(Y_test, y_pred, average='macro', zero_division=0):.4f}\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXmaSoktm9wE",
        "outputId": "a168a5fe-858e-45ce-bc4c-afa5ea94c711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting linguistic features...\n",
            "Linguistic features shape: (28619, 17)\n",
            "Combining BERT [CLS] and linguistic features...\n",
            "Combined BERT+Ling shape: (28619, 768)\n",
            "Splitting data into train/test sets...\n",
            "Train features shape: (21464, 768), Test features shape: (7155, 768)\n",
            "Scaling combined BERT+Ling features...\n",
            "Scaled features shape (sparse): (21464, 768)\n",
            "Generating TF-IDF features...\n",
            "TF-IDF Train shape: (21464, 23183)\n",
            "TF-IDF Test shape: (7155, 23183)\n",
            "Combining TF-IDF and Scaled (BERT+Ling) features...\n",
            "Final Combined Train shape: (21464, 23951)\n",
            "Final Combined Test shape: (7155, 23951)\n",
            "\n",
            "Training Logistic Regression model...\n",
            "\n",
            "Evaluating Logistic Regression model...\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89      3746\n",
            "           1       0.87      0.88      0.87      3409\n",
            "\n",
            "    accuracy                           0.88      7155\n",
            "   macro avg       0.88      0.88      0.88      7155\n",
            "weighted avg       0.88      0.88      0.88      7155\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3317  429]\n",
            " [ 424 2985]]\n",
            "\n",
            "Macro F1 Score: 0.8805\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuned"
      ],
      "metadata": {
        "id": "yru4imibxmcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tTQ2L_EAq1Na",
        "outputId": "65ab0ed6-9bb8-454a-b04c-9ef0057145a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5GwR22Eq5tY",
        "outputId": "3ac600f2-a521-4b71-ae2a-e3c6b1c70eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.14)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from datasets import Dataset\n",
        "import evaluate\n",
        "import os\n",
        "\n",
        "BASE_BERT_MODEL_NAME = 'bert-base-uncased'\n",
        "FINETUNED_MODEL_DIR = \"./bert_sarcasm_finetuned\"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE_EMBEDDING = 32\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.25\n",
        "\n",
        "# Fine-tuning hyperparameters\n",
        "NUM_TRAIN_EPOCHS = 2 # Adjust as needed (2-4 is common)\n",
        "LEARNING_RATE = 2e-5\n",
        "TRAIN_BATCH_SIZE_FT = 16 # Fine-tuning train batch size\n",
        "EVAL_BATCH_SIZE_FT = 32 # Fine-tuning evaluation batch size\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "df['is_sarcastic'] = df['is_sarcastic'].astype(int)\n",
        "df['clean_headline'] = df['clean_headline'].astype(str)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 1. Initial Data Split ---\n",
        "print(\"Splitting data into train/test sets...\")\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    stratify=df['is_sarcastic'],\n",
        "    random_state=42\n",
        ")\n",
        "# Store indices for later use\n",
        "idx_train = train_df.index\n",
        "idx_test = test_df.index\n",
        "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")\n",
        "\n",
        "# --- 2. Fine-Tune BERT ---\n",
        "print(\"\\n--- Step 2: Fine-Tuning BERT ---\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_BERT_MODEL_NAME)\n",
        "\n",
        "# Prepare datasets for Hugging Face Trainer\n",
        "train_dataset_hf = Dataset.from_pandas(train_df[['clean_headline', 'is_sarcastic']])\n",
        "test_dataset_hf = Dataset.from_pandas(test_df[['clean_headline', 'is_sarcastic']])\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['clean_headline'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=MAX_LENGTH\n",
        "    )\n",
        "\n",
        "# Apply tokenization\n",
        "print(\"Tokenizing datasets for fine-tuning...\")\n",
        "train_dataset_hf = train_dataset_hf.map(tokenize_function, batched=True)\n",
        "test_dataset_hf = test_dataset_hf.map(tokenize_function, batched=True)\n",
        "\n",
        "# Rename label column and set format\n",
        "train_dataset_hf = train_dataset_hf.rename_column(\"is_sarcastic\", \"labels\")\n",
        "test_dataset_hf = test_dataset_hf.rename_column(\"is_sarcastic\", \"labels\")\n",
        "columns_to_keep_hf = ['input_ids', 'token_type_ids', 'attention_mask', 'labels']\n",
        "train_dataset_hf.set_format(type='torch', columns=columns_to_keep_hf)\n",
        "test_dataset_hf.set_format(type='torch', columns=columns_to_keep_hf)\n",
        "\n",
        "# Load model for sequence classification\n",
        "print(f\"Loading base model '{BASE_BERT_MODEL_NAME}' for fine-tuning...\")\n",
        "model_for_finetuning = AutoModelForSequenceClassification.from_pretrained(\n",
        "    BASE_BERT_MODEL_NAME,\n",
        "    num_labels=2 # Binary classification (sarcastic/not sarcastic)\n",
        ")\n",
        "# Move model to device BEFORE defining Trainer if possible\n",
        "model_for_finetuning.to(device)\n",
        "\n",
        "# Define evaluation metrics\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    # Detach tensors and move to CPU if necessary before numpy conversion\n",
        "    if isinstance(labels, torch.Tensor): labels = labels.cpu().numpy()\n",
        "    if isinstance(logits, torch.Tensor): logits = logits.cpu().numpy()\n",
        "\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "# Define Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=FINETUNED_MODEL_DIR,\n",
        "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=TRAIN_BATCH_SIZE_FT,\n",
        "    per_device_eval_batch_size=EVAL_BATCH_SIZE_FT,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    evaluation_strategy=\"epoch\", # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",       # Save checkpoint at the end of each epoch\n",
        "    logging_strategy=\"epoch\",    # Log metrics at the end of each epoch\n",
        "    load_best_model_at_end=True, # Load the best checkpoint based on metric_for_best_model\n",
        "    metric_for_best_model=\"f1\",  # Use F1 score to determine the best model\n",
        "    greater_is_better=True,      # Higher F1 is better\n",
        "    report_to=\"none\",            # Disable wandb/tensorboard reporting if not needed\n",
        "    # no_cuda= (device.type == 'cpu') # Explicitly tell trainer if no cuda\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model_for_finetuning, # Model already on device\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_hf,\n",
        "    eval_dataset=test_dataset_hf, # Using test set for evaluation during fine-tuning\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Start fine-tuning\n",
        "print(\"Starting fine-tuning process...\")\n",
        "trainer.train()\n",
        "print(\"Fine-tuning finished.\")\n",
        "\n",
        "# Explicitly save the best model found by the Trainer\n",
        "print(f\"Saving the best fine-tuned model to {FINETUNED_MODEL_DIR}...\")\n",
        "trainer.save_model(FINETUNED_MODEL_DIR)\n",
        "tokenizer.save_pretrained(FINETUNED_MODEL_DIR) # Save tokenizer with the model\n",
        "\n",
        "print(\"Evaluating the best fine-tuned model...\")\n",
        "eval_results = trainer.evaluate(test_dataset_hf)\n",
        "print(\"Fine-tuning Evaluation Results:\", eval_results)\n",
        "\n",
        "\n",
        "# --- 3. Load Fine-Tuned Encoder and Extract Embeddings ---\n",
        "print(\"\\n--- Step 3: Extracting [CLS] Embeddings from Fine-Tuned Model ---\")\n",
        "\n",
        "# Load the fine-tuned model's base encoder part\n",
        "print(f\"Loading fine-tuned encoder from {FINETUNED_MODEL_DIR}...\")\n",
        "try:\n",
        "    # Load the full classification model first\n",
        "    fine_tuned_classifier = AutoModelForSequenceClassification.from_pretrained(FINETUNED_MODEL_DIR)\n",
        "    # Access the base model (encoder)\n",
        "    if hasattr(fine_tuned_classifier, 'bert'):\n",
        "        bert_encoder_finetuned = fine_tuned_classifier.bert\n",
        "    elif hasattr(fine_tuned_classifier, 'roberta'):\n",
        "         bert_encoder_finetuned = fine_tuned_classifier.roberta\n",
        "    # Add checks for other architectures if needed\n",
        "    else:\n",
        "         # Fallback: try loading AutoModel directly (might work if saved that way)\n",
        "         print(\"Could not find standard base model attribute, trying AutoModel directly...\")\n",
        "         bert_encoder_finetuned = AutoModel.from_pretrained(FINETUNED_MODEL_DIR)\n",
        "\n",
        "    bert_encoder_finetuned.to(device) # Ensure it's on the correct device\n",
        "    bert_encoder_finetuned.eval()     # Set to evaluation mode\n",
        "    # Reload tokenizer just to be sure it matches the saved model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL_DIR)\n",
        "    print(\"Fine-tuned encoder loaded successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading fine-tuned encoder: {e}\")\n",
        "    print(f\"Falling back to base '{BASE_BERT_MODEL_NAME}'. Embeddings will NOT be from fine-tuned model.\")\n",
        "    # Load base model as fallback\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_BERT_MODEL_NAME)\n",
        "    bert_encoder_finetuned = AutoModel.from_pretrained(BASE_BERT_MODEL_NAME)\n",
        "    bert_encoder_finetuned.to(device)\n",
        "    bert_encoder_finetuned.eval()\n",
        "\n",
        "# Function to Get BERT [CLS] Embeddings (same as before)\n",
        "def get_bert_cls_embeddings(texts, model, tokenizer, device, max_length, batch_size):\n",
        "    \"\"\"Generates [CLS] token embeddings for a list of texts.\"\"\"\n",
        "    all_cls_embeddings = []\n",
        "    model.eval() # Ensure model is in eval mode\n",
        "    print(f\"Generating embeddings in batches of {batch_size}...\")\n",
        "    num_batches = (len(texts) + batch_size - 1) // batch_size\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(\n",
        "            batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length\n",
        "        ).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "        all_cls_embeddings.append(cls_embeddings.cpu().numpy())\n",
        "        current_batch_num = (i // batch_size) + 1\n",
        "        if current_batch_num % 50 == 0 or current_batch_num == num_batches:\n",
        "             print(f\"  Processed batch {current_batch_num}/{num_batches}\")\n",
        "    print(\"Finished generating embeddings.\")\n",
        "    return np.vstack(all_cls_embeddings)\n",
        "\n",
        "# Generate embeddings using the FINE-TUNED encoder for the ENTIRE dataset\n",
        "print(\"Generating BERT [CLS] embeddings using the fine-tuned model...\")\n",
        "X_bert_finetuned = get_bert_cls_embeddings(\n",
        "    df['clean_headline'].tolist(), # Use full dataset text\n",
        "    bert_encoder_finetuned,        # Use the fine-tuned encoder\n",
        "    tokenizer,                     # Use the corresponding tokenizer\n",
        "    device,\n",
        "    MAX_LENGTH,\n",
        "    BATCH_SIZE_EMBEDDING\n",
        ")\n",
        "print(\"Fine-tuned BERT [CLS] embeddings shape:\", X_bert_finetuned.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6e6de003e2ee43f9b989434377903124",
            "d301c1cfcb0b4850b4307d316557ae85",
            "af1a82f5af4e4c719c8718ff1a0439a1",
            "ff1e583620ca49f9b1b52373eecd1fa1",
            "6ef370a29ef1439785a8ad23b73a602d",
            "8ef65344776c4b4197af7d4763a64e81",
            "dde20fd61c72445d9c2d2a9bd8eaec29",
            "389817bc18f44cd5b62913659b3e9cce",
            "a3a7184ff0214483a9d0868ce97af5c8",
            "a96e888fcf034d3faa72115981917cd5",
            "935f8910896942e6b2ea8f296d1aff65",
            "f9db96ced2b74e938dd590c6d197f9e0",
            "da904641b1794d2d825b555599ebe6d9",
            "99c299edfe02455cbd75f45af2890ef0",
            "89235190070b488bba5dee2e6bada0e5",
            "5db804535cbf45e8832ec526cda42a26",
            "5c111414053d425786ac9a82d4515f5b",
            "544c7bb07dd04feea6757e9e8dc10db7",
            "f3d4f726fa7543d993371422fde61cdd",
            "3fd96b5f201046adbca7b06ce27353f2",
            "5449d729263f4edc8c40b8269c0d8197",
            "14a6fc2ef0804bbd81aeffd47dc4f4f4",
            "8730452593534eda965f26ae8e687cb7",
            "1e4a1c86a7bd408095b0c6d3ddf600c1",
            "3e7fd75719c84c848110adec9d8689ac",
            "86f9dadc70ea4ab5b8b942f5925e55c2",
            "74be3b4b08c1492e8ea725b919530284",
            "8c12f334753841fe892540ef869d13cb",
            "8f5bbebce7394aa8a2da044092bd2a67",
            "b2a629a545af426ca9c5b02985062e5d",
            "979aeea8c5c64591b78d5f8b270d44f2",
            "bf76e8f791564834abca9a3c40651d16",
            "13b4d6d817234b588e5398030ea98913",
            "30f14940268c404e826d01b0e2228cef",
            "c28a559c0fcf4495a5bcab6474aa33e0",
            "670d4e68abff4df19f34e2183730b1fa",
            "7bc64bcddc294b4b8129365c2ad6a606",
            "dff098e59cf843ec9933b98b4b6c3b67",
            "aacfffa46cf347aba8e8cba0f0791165",
            "8e79e8381dfb48e882125570f5b35753",
            "ee9467d222df4c56baa57b65288eb189",
            "2173341b715e4655bf9d1968b2385db1",
            "645ff2212bc945f08d48eafc79d886da",
            "4d5f4251908f4b25b0c57a92a4050e4a"
          ]
        },
        "id": "xAsapyxoxn3L",
        "outputId": "276207c6-6973-4e73-e991-65b8b7efcbd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Splitting data into train/test sets...\n",
            "Train size: 21464, Test size: 7155\n",
            "\n",
            "--- Step 2: Fine-Tuning BERT ---\n",
            "Tokenizing datasets for fine-tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/21464 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e6de003e2ee43f9b989434377903124"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7155 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9db96ced2b74e938dd590c6d197f9e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base model 'bert-base-uncased' for fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8730452593534eda965f26ae8e687cb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30f14940268c404e826d01b0e2228cef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-38-105714e504a4>:136: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning process...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2684' max='2684' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2684/2684 18:15, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.275800</td>\n",
              "      <td>0.201322</td>\n",
              "      <td>0.925786</td>\n",
              "      <td>0.925530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.122900</td>\n",
              "      <td>0.306013</td>\n",
              "      <td>0.922572</td>\n",
              "      <td>0.922068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning finished.\n",
            "Saving the best fine-tuned model to ./bert_sarcasm_finetuned...\n",
            "Evaluating the best fine-tuned model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='224' max='224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [224/224 00:48]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning Evaluation Results: {'eval_loss': 0.20132198929786682, 'eval_accuracy': 0.9257861635220126, 'eval_f1': 0.9255295596374782, 'eval_runtime': 49.069, 'eval_samples_per_second': 145.815, 'eval_steps_per_second': 4.565, 'epoch': 2.0}\n",
            "\n",
            "--- Step 3: Extracting [CLS] Embeddings from Fine-Tuned Model ---\n",
            "Loading fine-tuned encoder from ./bert_sarcasm_finetuned...\n",
            "Fine-tuned encoder loaded successfully.\n",
            "Generating BERT [CLS] embeddings using the fine-tuned model...\n",
            "Generating embeddings in batches of 32...\n",
            "  Processed batch 50/895\n",
            "  Processed batch 100/895\n",
            "  Processed batch 150/895\n",
            "  Processed batch 200/895\n",
            "  Processed batch 250/895\n",
            "  Processed batch 300/895\n",
            "  Processed batch 350/895\n",
            "  Processed batch 400/895\n",
            "  Processed batch 450/895\n",
            "  Processed batch 500/895\n",
            "  Processed batch 550/895\n",
            "  Processed batch 600/895\n",
            "  Processed batch 650/895\n",
            "  Processed batch 700/895\n",
            "  Processed batch 750/895\n",
            "  Processed batch 800/895\n",
            "  Processed batch 850/895\n",
            "  Processed batch 895/895\n",
            "Finished generating embeddings.\n",
            "Fine-tuned BERT [CLS] embeddings shape: (28619, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuned BERT CLS + Ling + tf-idf"
      ],
      "metadata": {
        "id": "Pt_i6WMdpXA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Prepare Features for Logistic Regression ---\n",
        "print(\"\\n--- Step 4: Preparing Features for Logistic Regression ---\")\n",
        "\n",
        "# Linguistic Features (from full dataset)\n",
        "print(\"Extracting linguistic features...\")\n",
        "ling_feature_names = ['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "                      'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "                      'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "                      'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']\n",
        "X_ling = df[ling_feature_names].values\n",
        "print(\"Linguistic features shape:\", X_ling.shape)\n",
        "\n",
        "# Combine Fine-tuned BERT [CLS] + Linguistic Features\n",
        "print(\"Combining fine-tuned BERT [CLS] and linguistic features...\")\n",
        "X_gling_finetuned = np.hstack([X_bert_finetuned, X_ling])\n",
        "print(\"Combined BERT+Ling shape:\", X_gling_finetuned.shape)\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "# Split combined features using the indices from the initial split\n",
        "X_train_gling = X_gling_finetuned[idx_train]\n",
        "X_test_gling = X_gling_finetuned[idx_test]\n",
        "Y_train = y[idx_train]\n",
        "Y_test = y[idx_test]\n",
        "print(f\"Train combined dense features shape: {X_train_gling.shape}\")\n",
        "print(f\"Test combined dense features shape: {X_test_gling.shape}\")\n",
        "\n",
        "# Feature Scaling (on combined BERT+Ling)\n",
        "print(\"Scaling combined BERT+Ling features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "X_train_sparse_scaled = csr_matrix(X_train_scaled)\n",
        "X_test_sparse_scaled = csr_matrix(X_test_scaled)\n",
        "print(\"Scaled features shape (sparse):\", X_train_sparse_scaled.shape)\n",
        "\n",
        "# TF-IDF Features (using original train/test split text)\n",
        "print(\"Generating TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer() # Optional limit\n",
        "# Fit on train text identified by idx_train\n",
        "X_train_tfidf = tfidf.fit_transform(df.loc[idx_train, 'clean_headline'])\n",
        "# Transform test text identified by idx_test\n",
        "X_test_tfidf = tfidf.transform(df.loc[idx_test, 'clean_headline'])\n",
        "print(\"TF-IDF Train shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# Final Feature Combination\n",
        "print(\"Combining TF-IDF and Scaled (Fine-tuned BERT+Ling) features...\")\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse_scaled])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse_scaled])\n",
        "print(\"Final Combined Train shape:\", X_train_combined.shape)\n",
        "print(\"Final Combined Test shape:\", X_test_combined.shape)\n",
        "\n",
        "\n",
        "# --- 5. Logistic Regression Model ---\n",
        "print(\"\\n--- Step 5: Logistic Regression Training and Evaluation ---\")\n",
        "\n",
        "print(\"Training Logistic Regression model...\")\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=42)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "print(\"\\nEvaluating Logistic Regression model...\")\n",
        "y_pred_lr = lr.predict(X_test_combined)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(Y_test, y_pred_lr, zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(Y_test, y_pred_lr, labels=lr.classes_)\n",
        "print(cm)\n",
        "\n",
        "print(f\"\\nMacro F1 Score: {f1_score(Y_test, y_pred_lr, average='macro', zero_division=0):.4f}\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV1ljfvXpWIU",
        "outputId": "6551a9f5-80d8-4045-b113-f4bf2577cfb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Preparing Features for Logistic Regression ---\n",
            "Extracting linguistic features...\n",
            "Linguistic features shape: (28619, 17)\n",
            "Combining fine-tuned BERT [CLS] and linguistic features...\n",
            "Combined BERT+Ling shape: (28619, 785)\n",
            "Train combined dense features shape: (21464, 785)\n",
            "Test combined dense features shape: (7155, 785)\n",
            "Scaling combined BERT+Ling features...\n",
            "Scaled features shape (sparse): (21464, 785)\n",
            "Generating TF-IDF features...\n",
            "TF-IDF Train shape: (21464, 23183)\n",
            "TF-IDF Test shape: (7155, 23183)\n",
            "Combining TF-IDF and Scaled (Fine-tuned BERT+Ling) features...\n",
            "Final Combined Train shape: (21464, 23968)\n",
            "Final Combined Test shape: (7155, 23968)\n",
            "\n",
            "--- Step 5: Logistic Regression Training and Evaluation ---\n",
            "Training Logistic Regression model...\n",
            "\n",
            "Evaluating Logistic Regression model...\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      3746\n",
            "           1       0.93      0.92      0.92      3409\n",
            "\n",
            "    accuracy                           0.93      7155\n",
            "   macro avg       0.93      0.93      0.93      7155\n",
            "weighted avg       0.93      0.93      0.93      7155\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3500  246]\n",
            " [ 282 3127]]\n",
            "\n",
            "Macro F1 Score: 0.9260\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuned BERT CLS Only"
      ],
      "metadata": {
        "id": "Iw5JzShXCItI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Prepare Features for Logistic Regression ---\n",
        "print(\"\\n--- Step 4: Preparing Features for Logistic Regression ---\")\n",
        "\n",
        "# Linguistic Features (from full dataset)\n",
        "print(\"Extracting linguistic features...\")\n",
        "ling_feature_names = ['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "                      'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "                      'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "                      'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']\n",
        "X_ling = df[ling_feature_names].values\n",
        "print(\"Linguistic features shape:\", X_ling.shape)\n",
        "\n",
        "# Combine Fine-tuned BERT [CLS] + Linguistic Features\n",
        "print(\"Combining fine-tuned BERT [CLS] and linguistic features...\")\n",
        "X_gling_finetuned = np.hstack([X_bert_finetuned, X_ling])\n",
        "print(\"Combined BERT+Ling shape:\", X_gling_finetuned.shape)\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "# Split combined features using the indices from the initial split\n",
        "X_train_gling = X_gling_finetuned[idx_train]\n",
        "X_test_gling = X_gling_finetuned[idx_test]\n",
        "Y_train = y[idx_train]\n",
        "Y_test = y[idx_test]\n",
        "print(f\"Train combined dense features shape: {X_train_gling.shape}\")\n",
        "print(f\"Test combined dense features shape: {X_test_gling.shape}\")\n",
        "\n",
        "# Feature Scaling (on combined BERT+Ling)\n",
        "print(\"Scaling combined BERT+Ling features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "X_train_sparse_scaled = csr_matrix(X_train_scaled)\n",
        "X_test_sparse_scaled = csr_matrix(X_test_scaled)\n",
        "print(\"Scaled features shape (sparse):\", X_train_sparse_scaled.shape)\n",
        "\n",
        "# TF-IDF Features (using original train/test split text)\n",
        "print(\"Generating TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer() # Optional limit\n",
        "# Fit on train text identified by idx_train\n",
        "X_train_tfidf = tfidf.fit_transform(df.loc[idx_train, 'clean_headline'])\n",
        "# Transform test text identified by idx_test\n",
        "X_test_tfidf = tfidf.transform(df.loc[idx_test, 'clean_headline'])\n",
        "print(\"TF-IDF Train shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# Final Feature Combination\n",
        "print(\"Combining TF-IDF and Scaled (Fine-tuned BERT+Ling) features...\")\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse_scaled])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse_scaled])\n",
        "print(\"Final Combined Train shape:\", X_train_combined.shape)\n",
        "print(\"Final Combined Test shape:\", X_test_combined.shape)\n",
        "\n",
        "\n",
        "# --- 5. Logistic Regression Model ---\n",
        "print(\"\\n--- Step 5: Logistic Regression Training and Evaluation ---\")\n",
        "\n",
        "print(\"Training Logistic Regression model...\")\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=42)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "print(\"\\nEvaluating Logistic Regression model...\")\n",
        "y_pred_lr = lr.predict(X_test_combined)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(Y_test, y_pred_lr, zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(Y_test, y_pred_lr, labels=lr.classes_)\n",
        "print(cm)\n",
        "\n",
        "print(f\"\\nMacro F1 Score: {f1_score(Y_test, y_pred_lr, average='macro', zero_division=0):.4f}\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f60e880f-5392-41c9-c7d9-b35c0677f519",
        "id": "NF8jU5UXCItJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Preparing Features for Logistic Regression ---\n",
            "Extracting linguistic features...\n",
            "Linguistic features shape: (28619, 17)\n",
            "Combining fine-tuned BERT [CLS] and linguistic features...\n",
            "Combined BERT+Ling shape: (28619, 785)\n",
            "Train combined dense features shape: (21464, 785)\n",
            "Test combined dense features shape: (7155, 785)\n",
            "Scaling combined BERT+Ling features...\n",
            "Scaled features shape (sparse): (21464, 785)\n",
            "Generating TF-IDF features...\n",
            "TF-IDF Train shape: (21464, 23183)\n",
            "TF-IDF Test shape: (7155, 23183)\n",
            "Combining TF-IDF and Scaled (Fine-tuned BERT+Ling) features...\n",
            "Final Combined Train shape: (21464, 23968)\n",
            "Final Combined Test shape: (7155, 23968)\n",
            "\n",
            "--- Step 5: Logistic Regression Training and Evaluation ---\n",
            "Training Logistic Regression model...\n",
            "\n",
            "Evaluating Logistic Regression model...\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      3746\n",
            "           1       0.93      0.92      0.92      3409\n",
            "\n",
            "    accuracy                           0.93      7155\n",
            "   macro avg       0.93      0.93      0.93      7155\n",
            "weighted avg       0.93      0.93      0.93      7155\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3500  246]\n",
            " [ 282 3127]]\n",
            "\n",
            "Macro F1 Score: 0.9260\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sBERT again"
      ],
      "metadata": {
        "id": "h5yDda3XO5nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer # Import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import evaluate # Hugging Face evaluation library (can keep for metric functions if desired)\n",
        "import time # To time embedding generation\n",
        "\n",
        "# --- Configuration ---\n",
        "SBERT_MODEL_NAME = 'all-MiniLM-L6-v2' # Popular Sentence-BERT model\n",
        "BATCH_SIZE_EMBEDDING = 64\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.25\n",
        "\n",
        "df['is_sarcastic'] = df['is_sarcastic'].astype(int)\n",
        "df['clean_headline'] = df['clean_headline'].astype(str)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 1. Initial Data Split ---\n",
        "print(\"\\n--- Step 1: Splitting data into train/test sets ---\")\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=TEST_SIZE, # Use TEST_SIZE variable\n",
        "    stratify=df['is_sarcastic'],\n",
        "    random_state=RANDOM_STATE # Use RANDOM_STATE variable\n",
        ")\n",
        "# Store indices for later use\n",
        "idx_train = train_df.index\n",
        "idx_test = test_df.index\n",
        "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")\n",
        "\n",
        "# --- 2. Generate Sentence-BERT Embeddings (Contrastive Learning based) ---\n",
        "print(\"\\n--- Step 2: Generating Sentence-BERT Embeddings ---\")\n",
        "\n",
        "# Load a pre-trained Sentence Transformer model\n",
        "print(f\"Loading Sentence-BERT model: '{SBERT_MODEL_NAME}'...\")\n",
        "sbert_model = SentenceTransformer(SBERT_MODEL_NAME, device=device)\n",
        "print(\"Sentence-BERT model loaded.\")\n",
        "\n",
        "# Generate embeddings for the ENTIRE dataset's headlines\n",
        "print(\"Generating SBERT embeddings for all headlines...\")\n",
        "start_time = time.time()\n",
        "# Use model.encode() which handles tokenization and pooling internally\n",
        "X_sbert = sbert_model.encode(\n",
        "    df['clean_headline'].tolist(),\n",
        "    batch_size=BATCH_SIZE_EMBEDDING,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True # Get numpy array directly\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Finished generating embeddings in {end_time - start_time:.2f} seconds.\")\n",
        "print(\"SBERT embeddings shape:\", X_sbert.shape)\n",
        "\n",
        "# --- 3. Prepare Features for Logistic Regression ---\n",
        "print(\"\\n--- Step 3: Preparing Features for Logistic Regression ---\")\n",
        "\n",
        "# Linguistic Features (from full dataset)\n",
        "print(\"Extracting linguistic features...\")\n",
        "ling_feature_names = ['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "                      'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "                      'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "                      'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']\n",
        "# Ensure all ling feature columns exist in the DataFrame\n",
        "missing_ling_cols = [col for col in ling_feature_names if col not in df.columns]\n",
        "if missing_ling_cols:\n",
        "    raise ValueError(f\"Missing linguistic feature columns in DataFrame: {missing_ling_cols}\")\n",
        "\n",
        "X_ling = df[ling_feature_names].values\n",
        "print(\"Linguistic features shape:\", X_ling.shape)\n",
        "\n",
        "# Combine SBERT Embeddings + Linguistic Features\n",
        "print(\"Combining SBERT embeddings and linguistic features...\")\n",
        "# Make sure shapes are compatible for hstack: (n_samples, n_features_sbert) and (n_samples, n_features_ling)\n",
        "if X_sbert.shape[0] != X_ling.shape[0]:\n",
        "     raise ValueError(f\"Mismatch in number of samples between SBERT ({X_sbert.shape[0]}) and Ling ({X_ling.shape[0]}) features.\")\n",
        "X_gling_sbert = np.hstack([X_sbert, X_ling])\n",
        "print(\"Combined SBERT+Ling shape:\", X_gling_sbert.shape)\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "# Split combined features using the indices from the initial split\n",
        "X_train_gling = X_gling_sbert[idx_train]\n",
        "X_test_gling = X_gling_sbert[idx_test]\n",
        "Y_train = y[idx_train]\n",
        "Y_test = y[idx_test]\n",
        "print(f\"Train combined dense features shape: {X_train_gling.shape}\")\n",
        "print(f\"Test combined dense features shape: {X_test_gling.shape}\")\n",
        "\n",
        "# Feature Scaling (on combined SBERT+Ling)\n",
        "print(\"Scaling combined SBERT+Ling features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "X_train_sparse_scaled = csr_matrix(X_train_scaled) # Convert to sparse for hstack\n",
        "X_test_sparse_scaled = csr_matrix(X_test_scaled)   # Convert to sparse for hstack\n",
        "print(\"Scaled features shape (sparse):\", X_train_sparse_scaled.shape)\n",
        "\n",
        "# TF-IDF Features (using original train/test split text)\n",
        "print(\"Generating TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer() # Optional: limit max TF-IDF features\n",
        "# Fit on train text identified by idx_train\n",
        "X_train_tfidf = tfidf.fit_transform(df.loc[idx_train, 'clean_headline'])\n",
        "# Transform test text identified by idx_test\n",
        "X_test_tfidf = tfidf.transform(df.loc[idx_test, 'clean_headline'])\n",
        "print(\"TF-IDF Train shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# Final Feature Combination\n",
        "print(\"Combining TF-IDF and Scaled (SBERT+Ling) features...\")\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse_scaled]).tocsr() # Ensure CSR format\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse_scaled]).tocsr()   # Ensure CSR format\n",
        "print(\"Final Combined Train shape:\", X_train_combined.shape)\n",
        "print(\"Final Combined Test shape:\", X_test_combined.shape)\n",
        "\n",
        "\n",
        "# --- 4. Logistic Regression Model ---\n",
        "print(\"\\n--- Step 4: Logistic Regression Training and Evaluation ---\")\n",
        "\n",
        "print(\"Training Logistic Regression model...\")\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=RANDOM_STATE) # Changed solver for potential speedup with sparse data\n",
        "# Note: 'saga' solver also handles sparse data well and supports L1/L2/ElasticNet, but might be slower than liblinear for this scale.\n",
        "# 'sag' typically works better on dense data after scaling.\n",
        "# 'lbfgs' might struggle with the high dimensionality after TF-IDF.\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "print(\"\\nEvaluating Logistic Regression model...\")\n",
        "y_pred_lr = lr.predict(X_test_combined)\n",
        "y_prob_lr = lr.predict_proba(X_test_combined)[:, 1] # Get probabilities for class 1\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(Y_test, y_pred_lr, zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "# Use display labels for clarity if desired\n",
        "try:\n",
        "    from sklearn.metrics import ConfusionMatrixDisplay\n",
        "    import matplotlib.pyplot as plt\n",
        "    cm = confusion_matrix(Y_test, y_pred_lr, labels=lr.classes_)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Sarcastic', 'Sarcastic'])\n",
        "    disp.plot()\n",
        "    plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "    plt.show()\n",
        "except ImportError:\n",
        "    print(\"Install matplotlib and sklearn for confusion matrix visualization: pip install matplotlib\")\n",
        "    # Fallback to text display\n",
        "    cm = confusion_matrix(Y_test, y_pred_lr, labels=lr.classes_)\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "# Using evaluate library for F1 score\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "macro_f1 = f1_metric.compute(predictions=y_pred_lr, references=Y_test, average=\"macro\")[\"f1\"]\n",
        "print(f\"\\nMacro F1 Score (calculated using 'evaluate'): {macro_f1:.4f}\")\n",
        "# Or using sklearn directly\n",
        "print(f\"Macro F1 Score (calculated using 'sklearn'): {f1_score(Y_test, y_pred_lr, average='macro', zero_division=0):.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2e20739df2f646b08e4646ad14a3e668",
            "6c2aa876a0044f12b609082bf1921bb4",
            "073680b35f9941c091df6abbe409ac69",
            "9ef48d18c8424463aafb2c2ebf84e880",
            "c1b7159870fc413ca16575984f808cdb",
            "533dba8b0e3844388a0afc1eac9d04eb",
            "ac77d39fbb3d45ff8cdb58b0c24c5ddd",
            "62030c4ac53a4908bdd1a434e4a83594",
            "b5867c5c09ea4cc69e2678c446a27744",
            "654786cf14e140d9ac0cf8f4df27cbb0",
            "317ad9b759414580ae69286f138142bb",
            "5f1df533ea7f4633881b25937ab81cde",
            "f02fc3ad8e8e45ab9630a4ed52678b7e",
            "48d6a65ff6ce40a5b048b577532485b6",
            "7db68a39f10a40f186559040bbb7f920",
            "56b14402893d4253ad709db75029ae68",
            "ffa87c0db41e4c33b1fedd039e9a2e24",
            "a2ed559789374208acbc5df874177cb3",
            "8fbf40bd6a224f2a8ca6217d737052b9",
            "6130a41c34354a5c80642dbc1cfdcd5b",
            "3ced4e84c6b3409fa3387b361390b050",
            "c9153ebf460c4416b5d0121785fb2a49",
            "442ba27632e24ca0aeea60906aa5a647",
            "8a7a4a15cd5d419a983798678d07571a",
            "7a97698f979b427e8d57da3352ba4e48",
            "68e965d234394e7ea04d5dbf01d59c64",
            "f3c9ecf94660435e8e0b4020bc2f1d7b",
            "faa12f9c300a48ec83f028c3880b9f13",
            "b6020c6ab2de40f9af0953f8b2bef280",
            "ceeea5a823684e099159f22963dd8a80",
            "373ed23567e14e69b5836b6daf051769",
            "853951d8920a4fe4bad94c3f0674436f",
            "dc8a28e81fee4c9793196a069727a667",
            "2eafc0be41d14c4a8143a1317654dc0a",
            "7217fc50f965489c87bf8db89ef9de38",
            "49b208b477cd4a32b401abc286316d5d",
            "b987ddfd5a274c4eaefa51c4b4f6dccd",
            "54c5854b0e1945f596f9819108875703",
            "fc4787a460894d35b2317f5db809f317",
            "c6118d7158ff4f0baa238051b90ad31a",
            "5c46dd900a004830a8ef0706d0f48b0c",
            "89b0d91b8fdb4a7caf0f91635735fea9",
            "b288fd7cf8ee4c30be6e15a0e59e5b06",
            "58bf22e1a9b64d76b0dc1e4bf03363fb",
            "22c08e23df544cb687631b255e7af0e2",
            "a9246a37190c448fb12faac185e2c4e8",
            "1ae0a7752e114508815f31c940b05c2d",
            "ec97cf4077f74c7bb1ae8266a14e275e",
            "7bc2ff5d0e0743f7a159597a7de3d9c4",
            "d14ee0e9fa1e4a49ab569bc1b890c2d1",
            "5132219b9bd7456cbd33d06adc5b896a",
            "57d915eeb8b944d1b0d119cf94434700",
            "c790ba5508c64ff2b664b44bdffa8f44",
            "5566321a8abb4121be3e14dd670b0bb3",
            "c353cede79e24b47bc229f338bba00b9",
            "64e548c426294f4db5a143958f14a584",
            "785763ebd2824bb5a72f0d8c80f7c224",
            "f597c9180f4a477f9dfbfa54b9eb75d5",
            "c8e8cbe375ca4851967712f9164d78be",
            "23b22d84d8e74db5ab46ac27276fa4eb",
            "9084390bb1d84ceea7017701251fc37d",
            "feafd56152334920ac0a81d6212c1b9e",
            "7b2b5f5936e8447a83a0458ac09d1d89",
            "843bc301cd60456b9f2d29c4c8cf9510",
            "0731213ea7ad4f99a3e7e787d4920ec3",
            "2b80384495c947d6a83ec876da87a52d",
            "462f59abcd8e469baac4df8e62173859",
            "6a025ab990214c4da24670e3ecceda63",
            "fe492d3d5aca4a6f8a7d9edfdc26aa50",
            "d7133231b19547eba1042944d14848d9",
            "6f4810803cde4bb39c9c2f6fb800f28f",
            "181e8ad9e60449e796fc67b8e64f9314",
            "dc49a875d2ce440f8200889745f0c374",
            "757c1d3745444646aa988a283f628f60",
            "b5deebc484fa4b3380f8fa650238ec15",
            "37223a84831a422d87da916c04b45d26",
            "cd71ea863d504118b77d5cfaeedd40b9",
            "42afb7e32a3b4a519007d0009ec8bcee",
            "9e58c515472b4ebda7d7c9411999e4ed",
            "01dcdbcdc8874ebda5c345f4ed77bbb6",
            "5a2498c482ec4b0fb4aa903178178e18",
            "52aadfc757f44803bb74f05f3aca9305",
            "08e58f142fca47e9b649bc577b31a79d",
            "37a2959714f4435b8eb4332387efb1af",
            "cf8fa5ea2ee0407d8533d217b93aa801",
            "824bb5ca25cb48b3abe81b42bd89dd47",
            "3101abece24b4b839ca73f0ee776ad05",
            "e1210a49c989461996234296dd1d021d",
            "3a1a9ee54d2c4ac78297c7ba17ee3cc6",
            "7be321632b1341d98fc010a13cec8ca7",
            "30dcf402ad8249d39abdbc31abbccc36",
            "928d5165a44847a4b951266772ebb71d",
            "ac4e510535b246c49a1ba0ddff743f1d",
            "b561b13158844e39b9b2da4903f10849",
            "ff17af1bd03145da9885fc1af5d72ebe",
            "0720dd03d0fa4cccb4e2271470af9852",
            "702ceaa0264145ef9a257a71903f7b71",
            "c3afd951bcac456faf89a0b58629d080",
            "dc0071c403144592bce221841ce6c975",
            "f1fd908ea2ea4071bc032859de3aa545",
            "f05547e835ee428888007dddd48a5bef",
            "57e9170678fe45f6b7040ac8b50b7656",
            "f4c363249c554617a5fd761dd1c4e02f",
            "639691fd76e548a5927edffa0ab83064",
            "4bb17f84fe1b4995aa877969c11283a6",
            "c6d15ab6d98a497fbaec3cc28d0ac38e",
            "c7f83bc27d584048877cf8935282dfe0",
            "2246739513204dcc8d265b4b19cc4b19",
            "41ab02b8098a4814b49632dacea8186f",
            "8eb2dc526a4045828231dc9b30aa59ac",
            "aa83e1fc55ba449e9bba102cb8dc7ef9",
            "17e7ab4bb9634e7da0ea1afd4c760910",
            "6d27b18d03be4de09954e29ec6860e90",
            "914a0ba345424b0aa4318b962c5a0da8",
            "41296539f87647fd8e33bf2dd58f7169",
            "847c404e474d4621b34681b210f8bd52",
            "ab615c9d515d4ebf96531f49768a1c15",
            "72de6e14bd6d4f1eb1e9c518c437ad44",
            "9b5b3b714c524812bce6fda6e900433b",
            "dbecd00c99694e9fbdf7388073628508",
            "a50365466b074e1dbcabf06817f95013",
            "a418878c975c4b9a8a7ee5b36086743a",
            "1dfee1e24e7b4b2d912fad2234e7c212",
            "e2301fe073814a988dd88d2a13e6869f",
            "ef9ee4bfe3e1438ca5933b3d7e977a4a",
            "f7adacaf744c4aeb9ceaa93585fcf745",
            "b629f89fa6024b97ad285f818bbc4fa7",
            "6de148239523407cb1371f3733a5bbc3",
            "06c2ed5b13fa474bb0dff2ac0279ec30",
            "bffcc5130ad442fe8132aba69be957ec",
            "fa552193b76c4be883ce9ca460e04857",
            "847f55c9460d477e915b327ac89f0807"
          ]
        },
        "id": "_b7780vUOE6D",
        "outputId": "f6a3df14-d18c-495d-b95b-36ede5ace9c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Placeholder Data (Replace with your actual data loading) ---\n",
            "Placeholder DataFrame shape: (28619, 29)\n",
            "   is_sarcastic                                           headline  \\\n",
            "0             1  thirtysomething scientists unveil doomsday clo...   \n",
            "1             0  dem rep. totally nails why congress is falling...   \n",
            "2             0  eat your veggies: 9 deliciously different recipes   \n",
            "3             1  inclement weather prevents liar from getting t...   \n",
            "4             1  mother comes pretty close to using word 'strea...   \n",
            "\n",
            "                                        article_link  \\\n",
            "0  https://www.theonion.com/thirtysomething-scien...   \n",
            "1  https://www.huffingtonpost.com/entry/donna-edw...   \n",
            "2  https://www.huffingtonpost.com/entry/eat-your-...   \n",
            "3  https://local.theonion.com/inclement-weather-p...   \n",
            "4  https://www.theonion.com/mother-comes-pretty-c...   \n",
            "\n",
            "                                      clean_headline  \\\n",
            "0  thirtysomething scientists unveil doomsday clo...   \n",
            "1  dem rep. totally nails why congress is falling...   \n",
            "2  eat your veggies : 9 deliciously different rec...   \n",
            "3  inclement weather prevents liar from getting t...   \n",
            "4  mother comes pretty close to using word 'strea...   \n",
            "\n",
            "                                          pos_counts  text_length  noun_count  \\\n",
            "0  {'noun_count': 4, 'verb_count': 1, 'adj_count'...            8           4   \n",
            "1  {'noun_count': 5, 'verb_count': 2, 'adj_count'...           14           5   \n",
            "2  {'noun_count': 2, 'verb_count': 1, 'adj_count'...            8           2   \n",
            "3  {'noun_count': 3, 'verb_count': 3, 'adj_count'...            8           3   \n",
            "4  {'noun_count': 2, 'verb_count': 3, 'adj_count'...           10           2   \n",
            "\n",
            "   verb_count  adj_count  adv_count  ...  contrastive_marker   entropy  \\\n",
            "0           1          2          0  ...                   0  3.000000   \n",
            "1           2          3          1  ...                   0  3.807355   \n",
            "2           1          1          1  ...                   0  3.000000   \n",
            "3           3          0          0  ...                   0  3.000000   \n",
            "4           3          1          2  ...                   0  3.321928   \n",
            "\n",
            "   lexical_diversity  wrong_word_count  difficult_word_count  \\\n",
            "0                1.0                 2                     4   \n",
            "1                1.0                 3                     6   \n",
            "2                1.0                 2                     3   \n",
            "3                1.0                 2                     3   \n",
            "4                1.0                 3                     3   \n",
            "\n",
            "   lengthy_word_count  two_letter_words  single_letter_words  \\\n",
            "0                   0                 0                   61   \n",
            "1                   0                 0                   80   \n",
            "2                   0                 0                   50   \n",
            "3                   0                 0                   52   \n",
            "4                   0                 0                   62   \n",
            "\n",
            "   sentiment_incongruity                                     word_embedding  \n",
            "0                      0  [0.04490963, 0.22027238, -0.12828903, -0.12206...  \n",
            "1                      0  [-0.05677886, -0.22726436, -0.05362578, 0.1340...  \n",
            "2                      0  [-0.22747888, 0.11038363, 0.19199574, 0.142127...  \n",
            "3                      0  [-0.03541918, -0.118736744, -0.17343825, -0.15...  \n",
            "4                      0  [-0.23817676, 0.025476454, -0.03215033, -0.129...  \n",
            "\n",
            "[5 rows x 29 columns]\n",
            "Using device: cuda\n",
            "\n",
            "--- Step 1: Splitting data into train/test sets ---\n",
            "Train size: 21464, Test size: 7155\n",
            "\n",
            "--- Step 2: Generating Sentence-BERT Embeddings ---\n",
            "Loading Sentence-BERT model: 'all-MiniLM-L6-v2'...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e20739df2f646b08e4646ad14a3e668"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f1df533ea7f4633881b25937ab81cde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "442ba27632e24ca0aeea60906aa5a647"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2eafc0be41d14c4a8143a1317654dc0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22c08e23df544cb687631b255e7af0e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64e548c426294f4db5a143958f14a584"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "462f59abcd8e469baac4df8e62173859"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42afb7e32a3b4a519007d0009ec8bcee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a1a9ee54d2c4ac78297c7ba17ee3cc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1fd908ea2ea4071bc032859de3aa545"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa83e1fc55ba449e9bba102cb8dc7ef9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence-BERT model loaded.\n",
            "Generating SBERT embeddings for all headlines...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/448 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a418878c975c4b9a8a7ee5b36086743a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished generating embeddings in 14.88 seconds.\n",
            "SBERT embeddings shape: (28619, 384)\n",
            "\n",
            "--- Step 3: Preparing Features for Logistic Regression ---\n",
            "Extracting linguistic features...\n",
            "Linguistic features shape: (28619, 17)\n",
            "Combining SBERT embeddings and linguistic features...\n",
            "Combined SBERT+Ling shape: (28619, 401)\n",
            "Train combined dense features shape: (21464, 401)\n",
            "Test combined dense features shape: (7155, 401)\n",
            "Scaling combined SBERT+Ling features...\n",
            "Scaled features shape (sparse): (21464, 401)\n",
            "Generating TF-IDF features...\n",
            "TF-IDF Train shape: (21464, 23183)\n",
            "TF-IDF Test shape: (7155, 23183)\n",
            "Combining TF-IDF and Scaled (SBERT+Ling) features...\n",
            "Final Combined Train shape: (21464, 23584)\n",
            "Final Combined Test shape: (7155, 23584)\n",
            "\n",
            "--- Step 4: Logistic Regression Training and Evaluation ---\n",
            "Training Logistic Regression model...\n",
            "\n",
            "Evaluating Logistic Regression model...\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87      3746\n",
            "           1       0.86      0.86      0.86      3409\n",
            "\n",
            "    accuracy                           0.86      7155\n",
            "   macro avg       0.86      0.86      0.86      7155\n",
            "weighted avg       0.86      0.86      0.86      7155\n",
            "\n",
            "\n",
            "Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Macro F1 Score (calculated using 'evaluate'): 0.8638\n",
            "Macro F1 Score (calculated using 'sklearn'): 0.8638\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple NN"
      ],
      "metadata": {
        "id": "qOzwOlQAGrYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup X and Y vector here"
      ],
      "metadata": {
        "id": "RtcEHtU5a0pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_glove = np.vstack(df['word_embedding'].values)\n",
        "X_ling = df[['text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'dale_chall_score',\n",
        "             'sentiment_score', 'char_count', 'capital_char_count', 'capital_word_count',\n",
        "             'stopword_count', 'stopwords_vs_words', 'contrastive_marker', 'entropy',\n",
        "             'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count']].values\n",
        "\n",
        "X_gling = np.hstack([X_glove, X_ling])\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_train_gling, X_test_gling, Y_train, Y_test, idx_train, idx_test = train_test_split(\n",
        "    X_gling, y, df.index, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_gling)\n",
        "X_test_scaled = scaler.transform(X_test_gling)\n",
        "\n",
        "X_train_sparse = csr_matrix(X_train_scaled)\n",
        "X_test_sparse = csr_matrix(X_test_scaled)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf_all = tfidf.fit_transform(df['clean_headline'])\n",
        "\n",
        "X_train_tfidf = X_tfidf_all[idx_train]\n",
        "X_test_tfidf = X_tfidf_all[idx_test]\n",
        "\n",
        "# Combine\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_sparse])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_sparse])\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "lr.fit(X_train_combined, Y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_combined)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "print(f1_score(Y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "pwZs3hoNa5j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_combined.shape)"
      ],
      "metadata": {
        "id": "juaOIFSfgtdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continue training"
      ],
      "metadata": {
        "id": "tT1NQBzva6Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "nLMZ8eUBGsHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ca6972-b271-4073-d2ce-1a12f23ef413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_combined.toarray(), dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_combined.toarray(), dtype=torch.float32)\n",
        "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n",
        "Y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "IQ49tAWfGu38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No hidden layer"
      ],
      "metadata": {
        "id": "_DW5j6lDnF4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(input_dim, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "6GJ4Ews8LcOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One hidden layer"
      ],
      "metadata": {
        "id": "USmphqw9nHtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Uncomment as needed to use it\n",
        "\n",
        "# class SimpleNN(nn.Module):\n",
        "#     def __init__(self, input_dim):\n",
        "#         super(SimpleNN, self).__init__()\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(input_dim, 64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.3),\n",
        "#             nn.Linear(64, 2)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n"
      ],
      "metadata": {
        "id": "jgLO217XnDzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_combined.shape[1])\n",
        "model = SimpleNN(X_train_combined.shape[1])\n",
        "model.to(device)\n",
        "print(model(torch.randn(32, X_train_combined.shape[1]).to(device)).shape)"
      ],
      "metadata": {
        "id": "7gryRtWUVWHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cafffd02-947a-4f48-c93d-9e48aa825ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23968\n",
            "torch.Size([32, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "nGsmuGDWLffm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "None+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "EzVfpgganr9x",
        "outputId": "7a99a6fc-d631-4ed9-b3e2-a908cf4d7c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-dfd85c18edce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mNone\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN"
      ],
      "metadata": {
        "id": "B0cmAocxOgsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "None+1"
      ],
      "metadata": {
        "id": "Aig_xXEVOhqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "h5v2d_Zg1_XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "8MJ5f4ZgzZnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 30\n",
        "vocab_size = 25000\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df['clean_headline'], df['is_sarcastic'], random_state=42, stratify=df['is_sarcastic'])\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_seq_length, padding=\"post\")\n",
        "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_seq_length, padding=\"post\")\n",
        "print(X_train_seq.shape)"
      ],
      "metadata": {
        "id": "gC_mY9V-OgsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vocab_size = len(tokenizer.word_index)+1\n",
        "embedding_dim = 300\n",
        "hidden_dim = 32\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "C8VdH3YDOgsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokenizer vocabulary size:\", len(tokenizer.word_index))\n"
      ],
      "metadata": {
        "id": "6oDe-E9QOgsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensor = torch.tensor(X_train_seq, dtype=torch.long)\n",
        "test_tensor = torch.tensor(X_test_seq, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(train_tensor, torch.tensor(Y_train.values, dtype=torch.long))\n",
        "test_dataset = TensorDataset(test_tensor, torch.tensor(Y_test.values, dtype=torch.long))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "838Yxa_0OgsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < vocab_size and word in glove_dict:\n",
        "        embedding_matrix[i] = glove_dict[word]"
      ],
      "metadata": {
        "id": "QTlSZCqPOgsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim=2, pre_trained_embed=True):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding = None\n",
        "\n",
        "        if pre_trained_embed:\n",
        "          # not pretrained -> nn.Embedding(vocab_size, embedding_dim)\n",
        "          self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), freeze=False)\n",
        "        else:\n",
        "          self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.rnn(x) #(batch, seq_len, hidden)\n",
        "        x = self.fc(x[:, -1, :]) # (batch, hidden) -> (batch, 2)\n",
        "        return x"
      ],
      "metadata": {
        "id": "a4Oh6nO2OgsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True).to(device)"
      ],
      "metadata": {
        "id": "3Vx8bMjyOgsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = RNN(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True).to(device)"
      ],
      "metadata": {
        "id": "Fj73RhpVOgsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "xNi8HdMwOgsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "None+1"
      ],
      "metadata": {
        "id": "wEVjJ5RgOrLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "CRlGez3mLNUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "mOeaMM3AhJsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 25000\n",
        "embedding_dim = 300\n",
        "hidden_dim = 64\n",
        "max_seq_length = 30\n",
        "batch_size = 32\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df['clean_headline'], df['is_sarcastic'], random_state=42, stratify=df['is_sarcastic'])\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_seq_length, padding=\"post\")\n",
        "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_seq_length, padding=\"post\")\n",
        "print(X_train_seq.shape)"
      ],
      "metadata": {
        "id": "3C5iDJu-LHjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensor = torch.tensor(X_train_seq, dtype=torch.long)\n",
        "test_tensor = torch.tensor(X_test_seq, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(train_tensor, torch.tensor(Y_train.values, dtype=torch.long))\n",
        "test_dataset = TensorDataset(test_tensor, torch.tensor(Y_test.values, dtype=torch.long))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "WoeYrPj9Mo8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < vocab_size and word in glove_dict:\n",
        "        embedding_matrix[i] = glove_dict[word]"
      ],
      "metadata": {
        "id": "EMRd-JaBM8T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim=2, pre_trained_embed=True, bidirectional=False, freeze=False, num_layers=1):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        if pre_trained_embed:\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                torch.tensor(embedding_matrix, dtype=torch.float),\n",
        "                freeze=freeze\n",
        "            )\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
        "        self.fc = nn.Linear(lstm_output_dim, output_dim)\n",
        "        # self.fc = nn.Sequential(\n",
        "        #     nn.Linear(lstm_output_dim, 64),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Dropout(0.3),\n",
        "        #     nn.Linear(64, 2)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embed)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        else:\n",
        "            hidden = hidden[-1]\n",
        "\n",
        "        out = self.fc(hidden)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "LN2WsIwzLdOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMWithAttention(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim=2,\n",
        "                 pre_trained_embed=True, bidirectional=False, freeze=False, num_layers=1):\n",
        "        super(LSTMWithAttention, self).__init__()\n",
        "\n",
        "        if pre_trained_embed:\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                torch.tensor(embedding_matrix, dtype=torch.float),\n",
        "                freeze=freeze\n",
        "            )\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        # Attention layer\n",
        "        self.attention = nn.Linear(hidden_dim * self.num_directions, 1)\n",
        "\n",
        "        # Final FC layer\n",
        "        self.fc = nn.Linear(hidden_dim * self.num_directions, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)                     # (batch, seq_len, embed_dim)\n",
        "        output, (hidden, cell) = self.lstm(embed)     # output: (batch, seq_len, hidden*dir)\n",
        "\n",
        "        # Attention mechanism\n",
        "        attn_weights = torch.softmax(self.attention(output), dim=1)  # (batch, seq_len, 1)\n",
        "        context = torch.sum(attn_weights * output, dim=1)            # (batch, hidden*dir)\n",
        "\n",
        "        out = self.fc(context)  # classification head\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "HthyjaNsr_5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim=2, pre_trained_embed=True, bidirectional=False, freeze=False, num_layers=1):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        if pre_trained_embed:\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                torch.tensor(embedding_matrix, dtype=torch.float),\n",
        "                freeze=freeze\n",
        "            )\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.gru = nn.GRU(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        gru_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
        "        self.fc = nn.Linear(gru_output_dim, output_dim)\n",
        "\n",
        "        # Optional deeper FC version:\n",
        "        # self.fc = nn.Sequential(\n",
        "        #     nn.Linear(gru_output_dim, 1024),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Dropout(0.3),\n",
        "        #     nn.Linear(1024, output_dim)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)\n",
        "        output, hidden = self.gru(embed)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        else:\n",
        "            hidden = hidden[-1]\n",
        "\n",
        "        out = self.fc(hidden)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "a90oAEtMo9_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True, bidirectional=True, freeze=False,num_layers=1).to(device)\n",
        "#best_model = LSTM(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True, bidirectional=False, freeze=False).to(device)"
      ],
      "metadata": {
        "id": "EFnyhVXVMY7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "2_EVvBdUM0qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "None+1"
      ],
      "metadata": {
        "id": "8OBbLli3kRPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM with Features"
      ],
      "metadata": {
        "id": "iicdNjIp9i01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Glove"
      ],
      "metadata": {
        "id": "bKK8gUiSmy_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "handcrafted_features = [\n",
        "    'text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count',\n",
        "    'dale_chall_score', 'sentiment_score', 'char_count', 'capital_char_count',\n",
        "    'capital_word_count', 'stopword_count', 'stopwords_vs_words', 'contrastive_marker',\n",
        "    'entropy', 'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count'\n",
        "]\n",
        "\n",
        "# Tokenizer\n",
        "vocab_size = 25000\n",
        "max_seq_length = 30\n",
        "embedding_dim = 300\n",
        "hidden_dim = 64\n",
        "batch_size = 32\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['clean_headline'])\n",
        "X_seq = pad_sequences(tokenizer.texts_to_sequences(df['clean_headline']), maxlen=max_seq_length, padding=\"post\")\n",
        "\n",
        "X_glove = np.vstack(df['word_embedding'].values)\n",
        "X_ling = df[handcrafted_features].values\n",
        "X_combined = np.hstack([X_glove, X_ling])\n",
        "\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_seq_train, X_seq_test, X_feat_train, X_feat_test, y_train, y_test = train_test_split(\n",
        "    X_seq, X_combined, y, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "b6xb0o0p9knD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With SentenceTransformer"
      ],
      "metadata": {
        "id": "A6YVksATm0Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# This assumes df['clean_headline'] exists\n",
        "X_bert = bert_model.encode(df['clean_headline'].tolist(), show_progress_bar=True)\n",
        "print(\"BERT embeddings shape:\", X_bert.shape)"
      ],
      "metadata": {
        "id": "0Ai1QEuGm3YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "handcrafted_features = [\n",
        "    'text_length', 'noun_count', 'verb_count', 'adj_count', 'adv_count',\n",
        "    'dale_chall_score', 'sentiment_score', 'char_count', 'capital_char_count',\n",
        "    'capital_word_count', 'stopword_count', 'stopwords_vs_words', 'contrastive_marker',\n",
        "    'entropy', 'lexical_diversity', 'sentiment_incongruity', 'difficult_word_count'\n",
        "]\n",
        "\n",
        "# Tokenizer\n",
        "vocab_size = 25000\n",
        "max_seq_length = 30\n",
        "embedding_dim = 300\n",
        "hidden_dim = 64\n",
        "batch_size = 32\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['clean_headline'])\n",
        "X_seq = pad_sequences(tokenizer.texts_to_sequences(df['clean_headline']), maxlen=max_seq_length, padding=\"post\")\n",
        "\n",
        "X_bert_stacked = np.vstack(X_bert)\n",
        "X_ling = df[handcrafted_features].values\n",
        "X_combined = np.hstack([X_bert_stacked, X_ling])\n",
        "\n",
        "y = df['is_sarcastic'].values\n",
        "\n",
        "X_seq_train, X_seq_test, X_feat_train, X_feat_test, y_train, y_test = train_test_split(\n",
        "    X_seq, X_combined, y, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "Qkp-pbxMnV-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rest"
      ],
      "metadata": {
        "id": "jiGL8yFrnYAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_feat_train_scaled = scaler.fit_transform(X_feat_train)\n",
        "X_feat_test_scaled = scaler.transform(X_feat_test)\n",
        "\n",
        "train_dataset = TensorDataset(\n",
        "    torch.tensor(X_seq_train, dtype=torch.long),\n",
        "    torch.tensor(X_feat_train_scaled, dtype=torch.float32),\n",
        "    torch.tensor(y_train, dtype=torch.long)\n",
        ")\n",
        "test_dataset = TensorDataset(\n",
        "    torch.tensor(X_seq_test, dtype=torch.long),\n",
        "    torch.tensor(X_feat_test_scaled, dtype=torch.float32),\n",
        "    torch.tensor(y_test, dtype=torch.long)\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "-8Fe6UIv9xVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_feat_test.shape)\n",
        "\n",
        "for i in train_loader:\n",
        "  print(i[0].shape, i[1].shape, i[2].shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "jgYyptif-P-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < vocab_size and word in glove_dict:\n",
        "        embedding_matrix[i] = glove_dict[word]"
      ],
      "metadata": {
        "id": "q02t91Pp-FKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMWithFeatures(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, extra_feat_dim,\n",
        "                 output_dim=2, pre_trained_embed=True, freeze=False, bidirectional=False, num_layers=1):\n",
        "        super(LSTMWithFeatures, self).__init__()\n",
        "\n",
        "        if pre_trained_embed:\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                torch.tensor(embedding_matrix, dtype=torch.float),\n",
        "                freeze=freeze\n",
        "            )\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "        self.hidden_dim = hidden_dim\n",
        "        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        #self.fc = nn.Linear(lstm_output_dim + extra_feat_dim, output_dim)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(lstm_output_dim + extra_feat_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "        print(f\"LSTM input dimension: {embedding_dim}\")\n",
        "        print(f\"LSTM hidden dimension: {hidden_dim}\")\n",
        "        print(f\"LSTM output dimension: {lstm_output_dim}\")\n",
        "        print(f\"extra_feat_dim: {extra_feat_dim}\")\n",
        "        print(f\"fc input dimension: {lstm_output_dim + extra_feat_dim}\")\n",
        "\n",
        "    def forward(self, x_seq, x_extra):\n",
        "        embed = self.embedding(x_seq)\n",
        "        output, (hidden, _) = self.lstm(embed)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        else:\n",
        "            hidden = hidden[-1]\n",
        "\n",
        "        combined = torch.cat((hidden, x_extra), dim=1)\n",
        "        return self.fc(combined)"
      ],
      "metadata": {
        "id": "AWPw_UJa90pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMWithFeatures(\n",
        "    vocab_size=len(tokenizer.word_index)+1,\n",
        "    embedding_dim=300,\n",
        "    hidden_dim=64,\n",
        "    extra_feat_dim=X_feat_train_scaled.shape[1],\n",
        "    pre_trained_embed=True,\n",
        "    freeze=False,\n",
        "    bidirectional=True,\n",
        "    num_layers=1\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "0hMbJGTj_B-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
        "patience = 8\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for seq, feat, labels in loader:\n",
        "            seq, feat, labels = seq.to(device), feat.to(device), labels.to(device)\n",
        "            outputs = model(seq, feat)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    print(f\"Test Macro F1: {f1:.4f}\")\n",
        "    return f1\n",
        "\n",
        "def train(model, train_loader, test_loader, epochs=20):\n",
        "    best_f1 = 0\n",
        "    no_improve = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        y_true, y_pred = [], []\n",
        "        for seq, feat, labels in train_loader:\n",
        "            seq, feat, labels = seq.to(device), feat.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(seq, feat)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        train_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        print(f\"\\nEpoch {epoch+1}\")\n",
        "        print(f\"Train Loss: {total_loss:.4f}\")\n",
        "        print(f\"Train F1: {train_f1:.4f}\")\n",
        "\n",
        "        val_f1 = evaluate(model, test_loader)\n",
        "        scheduler.step(val_f1)\n",
        "\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            no_improve = 0\n",
        "            print(\"Saving best model...\")\n",
        "            torch.save(model.state_dict(), \"lstm_with_features.pt\")\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "train(model, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "bqy5sqPS_Ryk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tmp = SimpleNN(X_train_combined.shape[1])\n",
        "#tmp = RNN(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True).to(device)\n",
        "tmp = LSTMWithFeatures(\n",
        "    vocab_size=len(tokenizer.word_index)+1,\n",
        "    embedding_dim=300,\n",
        "    hidden_dim=64,\n",
        "    extra_feat_dim=X_feat_train_scaled.shape[1],\n",
        "    pre_trained_embed=True,\n",
        "    freeze=False,\n",
        "    bidirectional=True,\n",
        "    num_layers=1\n",
        ").to(device)\n",
        "#tmp = LSTMWithAttention(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True, bidirectional=False, freeze=False,num_layers=1).to(device)\n",
        "#tmp = GRU(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True, bidirectional=True, freeze=False,num_layers=1).to(device)\n",
        "tmp.load_state_dict(torch.load(\"lstm_with_features.pt\"))\n",
        "evaluate(tmp, test_loader)"
      ],
      "metadata": {
        "id": "qkKybechF0ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "None+1"
      ],
      "metadata": {
        "id": "oczbXAhVfKDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "0I6_873Zwfvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df['clean_headline'], df['is_sarcastic'], random_state=42, stratify=df['is_sarcastic'])"
      ],
      "metadata": {
        "id": "MzRqyAqmwh6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(texts, max_len=30):\n",
        "    encoding = tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=max_len\n",
        "    )\n",
        "    return encoding['input_ids'], encoding['attention_mask']\n",
        "\n",
        "X_train_ids, X_train_mask = tokenize(X_train)\n",
        "X_test_ids, X_test_mask = tokenize(X_test)\n",
        "\n",
        "# Dataset\n",
        "train_dataset = TensorDataset(X_train_ids, X_train_mask, torch.tensor(Y_train.values))\n",
        "test_dataset = TensorDataset(X_test_ids, X_test_mask, torch.tensor(Y_test.values))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "6Cb2RQUuwsMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, freeze_bert=True):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.bert.config.hidden_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "        return self.fc(cls_output)\n",
        "\n",
        "# Init\n",
        "model = BERTClassifier(freeze_bert=False).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
        "patience = 5"
      ],
      "metadata": {
        "id": "_uFr-GlMwtz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, verbose, device):\n",
        "    model.eval()\n",
        "    y_pred, y_true = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for ids, masks, labels in test_loader:\n",
        "            ids, masks, labels = ids.to(device), masks.to(device), labels.to(device)\n",
        "            outputs = model(ids, masks)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    print(f\"Macro Test F1: {macro_f1:.4f}\")\n",
        "    return macro_f1\n",
        "\n",
        "# Train Function\n",
        "def train(model, train_loader, device, epochs=10):\n",
        "    best_f1 = 0\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        y_pred, y_true = [], []\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for ids, masks, labels in train_loader:\n",
        "            ids, masks, labels = ids.to(device), masks.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(ids, masks)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        print(f\"\\nEpoch {epoch+1}\")\n",
        "        print(f\"Train Loss: {running_loss:.4f}\")\n",
        "        print(f\"Train F1: {train_f1:.4f}\")\n",
        "\n",
        "        test_f1 = evaluate(model, test_loader, True, device)\n",
        "        scheduler.step(test_f1)\n",
        "\n",
        "        if test_f1 > best_f1:\n",
        "            best_f1 = test_f1\n",
        "            no_improve = 0\n",
        "            print(\"New best model! Saving...\")\n",
        "            torch.save(model.state_dict(), \"best_bert_model.pt\")\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "train(model, train_loader, device)"
      ],
      "metadata": {
        "id": "sU4kjjlCwv1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM w/ BERT"
      ],
      "metadata": {
        "id": "_1fRPDI-5WWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load BERT"
      ],
      "metadata": {
        "id": "9GFFx94L4nJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from transformers import AutoTokenizer, AutoModel # Use AutoModel for base encoder\n",
        "import random\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "BERT_MODEL_NAME = 'bert-base-uncased' # Or other BERT model\n",
        "MAX_SEQ_LENGTH = 64  # Adjust based on your data and BERT's limits\n",
        "BATCH_SIZE = 32\n",
        "LSTM_HIDDEN_DIM = 128 # You can tune this\n",
        "NUM_LSTM_LAYERS = 1\n",
        "BIDIRECTIONAL_LSTM = True\n",
        "LEARNING_RATE = 1e-4 # Learning rate for the LSTM/FC layers\n",
        "EPOCHS = 5 # Number of epochs to train LSTM/FC layers\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# --- Seed Setting ---\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "        # Ensure deterministic behavior\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(RANDOM_STATE)\n",
        "\n",
        "# --- Load Your Data ---\n",
        "# Replace this with your actual data loading\n",
        "# Ensure you have 'clean_headline' and 'is_sarcastic' columns\n",
        "# Example Dummy Data:\n",
        "df['is_sarcastic'] = df['is_sarcastic'].astype(int)\n",
        "df['clean_headline'] = df['clean_headline'].astype(str)\n",
        "# --- End Data Loading ---\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 1. Load Pre-trained BERT Model and Tokenizer ---\n",
        "print(f\"Loading BERT model: {BERT_MODEL_NAME}\")\n",
        "tokenizer_bert = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
        "bert_model = AutoModel.from_pretrained(BERT_MODEL_NAME)\n",
        "\n",
        "# --- FREEZE BERT parameters ---\n",
        "# We treat BERT purely as a feature extractor here\n",
        "for param in bert_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "bert_model.to(device) # Move BERT to the correct device\n",
        "bert_model.eval() # Set BERT to evaluation mode\n",
        "bert_hidden_size = bert_model.config.hidden_size\n",
        "print(f\"BERT hidden size: {bert_hidden_size}\")\n",
        "\n",
        "# --- 2. Data Splitting and Tokenization (using BERT Tokenizer) ---\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df['clean_headline'].tolist(), # Pass list of strings\n",
        "    df['is_sarcastic'].values,     # Pass numpy array\n",
        "    random_state=42,\n",
        "    stratify=df['is_sarcastic']\n",
        ")\n",
        "\n",
        "print(\"Tokenizing data with BERT tokenizer...\")\n",
        "# Tokenize function for BERT\n",
        "def tokenize_bert(texts, tokenizer, max_len):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        add_special_tokens=True, # Add [CLS] and [SEP]\n",
        "        max_length=max_len,\n",
        "        padding='max_length',    # Pad to max_len\n",
        "        truncation=True,         # Truncate longer sequences\n",
        "        return_attention_mask=True, # Return attention mask\n",
        "        return_tensors='pt'      # Return PyTorch tensors\n",
        "    )\n",
        "\n",
        "# Apply tokenization\n",
        "train_encodings = tokenize_bert(X_train, tokenizer_bert, MAX_SEQ_LENGTH)\n",
        "test_encodings = tokenize_bert(X_test, tokenizer_bert, MAX_SEQ_LENGTH)\n",
        "\n"
      ],
      "metadata": {
        "id": "RfxljhN75YbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "6EDIzY345FGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Create PyTorch Datasets and DataLoaders ---\n",
        "class SarcasmDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "        # Detach is important if encodings were created with grad tracking\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = SarcasmDataset(train_encodings, Y_train)\n",
        "test_dataset = SarcasmDataset(test_encodings, Y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")"
      ],
      "metadata": {
        "id": "SHTek-q444F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Define the LSTM Model using BERT Embeddings ---\n",
        "class BertLSTMClassifier(nn.Module):\n",
        "    def __init__(self, bert_model, lstm_hidden_dim, output_dim=2, num_layers=1, bidirectional=True, dropout_prob=0.3):\n",
        "        super(BertLSTMClassifier, self).__init__()\n",
        "\n",
        "        self.bert = bert_model\n",
        "        self.bert_hidden_size = bert_model.config.hidden_size\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # LSTM layer - input size is BERT's hidden dimension\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.bert_hidden_size,\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True, # Input shape: (batch, seq_len, features)\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout_prob if num_layers > 1 else 0 # Add dropout between LSTM layers if num_layers > 1\n",
        "        )\n",
        "\n",
        "        # Calculate the input dimension for the fully connected layer\n",
        "        lstm_output_dim = lstm_hidden_dim * 2 if bidirectional else lstm_hidden_dim\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_prob), # Apply dropout before the final layer\n",
        "            nn.Linear(lstm_output_dim, output_dim)\n",
        "            # Optional: Add more layers if needed\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(some_intermediate_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Pass data through BERT (ensure BERT is frozen and in eval mode if desired)\n",
        "        # No gradient calculation needed for BERT forward pass here\n",
        "        with torch.no_grad():\n",
        "            bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            # bert_embeddings shape: (batch_size, seq_length, bert_hidden_size)\n",
        "            bert_embeddings = bert_outputs.last_hidden_state\n",
        "\n",
        "        # Pass BERT embeddings through LSTM\n",
        "        # lstm_out shape: (batch_size, seq_length, num_directions * hidden_dim)\n",
        "        # hidden shape: (num_layers * num_directions, batch_size, hidden_dim)\n",
        "        lstm_out, (hidden, cell) = self.lstm(bert_embeddings)\n",
        "\n",
        "        # Extract the final hidden state (or combine directions for bidirectional)\n",
        "        if self.bidirectional:\n",
        "            # Concatenate the final hidden states from forward (hidden[-2]) and backward (hidden[-1]) directions\n",
        "            final_hidden_state = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "            # Alternative: Use the last output token's hidden state from LSTM `lstm_out[:, -1, :]`\n",
        "            # final_hidden_state = lstm_out[:, -1, :] # Shape: (batch_size, num_directions * hidden_dim)\n",
        "        else:\n",
        "            # Get the hidden state of the last layer\n",
        "            final_hidden_state = hidden[-1,:,:]\n",
        "            # Alternative: Use the last output token's hidden state from LSTM `lstm_out[:, -1, :]`\n",
        "            # final_hidden_state = lstm_out[:, -1, :] # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Pass the final hidden state through the fully connected layer\n",
        "        logits = self.fc(final_hidden_state) # Shape: (batch_size, output_dim)\n",
        "        return logits\n",
        "\n",
        "# --- 5. Initialize Model, Loss Function, Optimizer ---\n",
        "model = BertLSTMClassifier(\n",
        "    bert_model=bert_model, # Pass the frozen BERT model\n",
        "    lstm_hidden_dim=LSTM_HIDDEN_DIM,\n",
        "    num_layers=NUM_LSTM_LAYERS,\n",
        "    bidirectional=BIDIRECTIONAL_LSTM\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Only optimize parameters of the LSTM and FC layer (BERT is frozen)\n",
        "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
        "\n",
        "# --- 6. Training Loop ---\n",
        "print(\"\\n--- Starting Training ---\")\n",
        "model.train() # Set model to training mode (affects dropout, etc.)\n",
        "# Note: BERT part remains in eval mode internally due to the earlier bert_model.eval() call if you want it fully frozen.\n",
        "# If you intended BERT to use its dropout during this phase (less common when frozen), you'd need more careful handling.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        # Move batch to device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy (optional, for monitoring)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 50 == 0: # Print progress every 50 batches\n",
        "            print(f\"Epoch [{epoch+1}/{EPOCHS}], Batch [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS} Summary:\")\n",
        "    print(f\"  Average Training Loss: {avg_epoch_loss:.4f}\")\n",
        "    print(f\"  Training Accuracy: {epoch_accuracy:.4f}\")\n",
        "\n",
        "# --- 7. Evaluation Loop ---\n",
        "print(\"\\n--- Evaluating on Test Set ---\")\n",
        "model.eval() # Set model to evaluation mode\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculations\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# --- 8. Report Results ---\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=['Not Sarcastic', 'Sarcastic'], zero_division=0))\n",
        "\n",
        "macro_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "weighted_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"\\nMacro F1 Score: {macro_f1:.4f}\")\n",
        "print(f\"Weighted F1 Score: {weighted_f1:.4f}\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "id": "EtXf9nf_4xHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tuned BERT"
      ],
      "metadata": {
        "id": "n7gbTZTYDogg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup # Added scheduler\n",
        "import random\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "BERT_MODEL_NAME = 'bert-base-uncased' # Or other BERT model\n",
        "MAX_SEQ_LENGTH = 64  # Adjust based on your data and BERT's limits\n",
        "BATCH_SIZE = 16 # Smaller batch size might be needed due to memory usage of fine-tuning BERT\n",
        "LSTM_HIDDEN_DIM = 128 # You can tune this\n",
        "NUM_LSTM_LAYERS = 1\n",
        "BIDIRECTIONAL_LSTM = True\n",
        "# *** CRITICAL: Use a small learning rate for fine-tuning ***\n",
        "LEARNING_RATE = 2e-5 # Typical fine-tuning learning rate for BERT\n",
        "EPOCHS = 3 # Fine-tuning often requires fewer epochs (2-4 is common)\n",
        "RANDOM_STATE = 42\n",
        "GRADIENT_CLIP_VALUE = 1.0 # Optional gradient clipping\n",
        "\n",
        "# --- Seed Setting ---\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "        # Ensure deterministic behavior\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(RANDOM_STATE)\n",
        "\n",
        "df['is_sarcastic'] = df['is_sarcastic'].astype(int)\n",
        "df['clean_headline'] = df['clean_headline'].astype(str)\n",
        "# --- End Data Loading ---\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 1. Load Pre-trained BERT Model and Tokenizer ---\n",
        "print(f\"Loading BERT model: {BERT_MODEL_NAME} for fine-tuning\")\n",
        "tokenizer_bert = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
        "# Load the base model, gradients will be enabled by default\n",
        "bert_model = AutoModel.from_pretrained(BERT_MODEL_NAME)\n",
        "\n",
        "# *** BERT parameters are NOT frozen this time ***\n",
        "# for param in bert_model.parameters():\n",
        "#     param.requires_grad = True # This is the default, no need to set explicitly\n",
        "\n",
        "bert_hidden_size = bert_model.config.hidden_size\n",
        "print(f\"BERT hidden size: {bert_hidden_size}\")\n",
        "\n",
        "# --- 2. Data Splitting and Tokenization (using BERT Tokenizer) ---\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df['clean_headline'].tolist(), # Pass list of strings\n",
        "    df['is_sarcastic'].values,     # Pass numpy array\n",
        "    test_size=0.25,                # Using 25% for test\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=df['is_sarcastic']\n",
        ")\n",
        "\n",
        "print(\"Tokenizing data with BERT tokenizer...\")\n",
        "# Tokenize function for BERT (same as before)\n",
        "def tokenize_bert(texts, tokenizer, max_len):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "train_encodings = tokenize_bert(X_train, tokenizer_bert, MAX_SEQ_LENGTH)\n",
        "test_encodings = tokenize_bert(X_test, tokenizer_bert, MAX_SEQ_LENGTH)\n",
        "\n",
        "# --- 3. Create PyTorch Datasets and DataLoaders ---\n",
        "# SarcasmDataset class remains the same as the previous example\n",
        "class SarcasmDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Ensure tensors are returned correctly\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = SarcasmDataset(train_encodings, Y_train)\n",
        "test_dataset = SarcasmDataset(test_encodings, Y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")\n",
        "\n",
        "# --- 4. Define the Fine-Tuning Model (BERT + LSTM + Classifier) ---\n",
        "class BertLSTMFineTuneClassifier(nn.Module):\n",
        "    def __init__(self, bert_model, lstm_hidden_dim, output_dim=2, num_layers=1, bidirectional=True, dropout_prob=0.3):\n",
        "        super(BertLSTMFineTuneClassifier, self).__init__()\n",
        "\n",
        "        self.bert = bert_model # The BERT model (not frozen)\n",
        "        self.bert_hidden_size = bert_model.config.hidden_size\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.bert_hidden_size,\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout_prob if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        lstm_output_dim = lstm_hidden_dim * 2 if bidirectional else lstm_hidden_dim\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(lstm_output_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Pass data through BERT - gradients WILL flow back this time\n",
        "        # NO torch.no_grad() here\n",
        "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        bert_embeddings = bert_outputs.last_hidden_state # (batch, seq_len, bert_hidden)\n",
        "\n",
        "        # Pass BERT embeddings through LSTM\n",
        "        lstm_out, (hidden, cell) = self.lstm(bert_embeddings) # lstm_out: (batch, seq_len, lstm_hidden * num_dir)\n",
        "\n",
        "        # Extract final hidden state\n",
        "        if self.bidirectional:\n",
        "            # Concatenate final forward and backward hidden states\n",
        "            final_hidden_state = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        else:\n",
        "            final_hidden_state = hidden[-1,:,:]\n",
        "\n",
        "        # Classifier head\n",
        "        logits = self.fc(final_hidden_state)\n",
        "        return logits\n",
        "\n",
        "# --- 5. Initialize Model, Loss Function, Optimizer, Scheduler ---\n",
        "model = BertLSTMFineTuneClassifier(\n",
        "    bert_model=bert_model, # Pass the BERT model instance\n",
        "    lstm_hidden_dim=LSTM_HIDDEN_DIM,\n",
        "    num_layers=NUM_LSTM_LAYERS,\n",
        "    bidirectional=BIDIRECTIONAL_LSTM\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer: AdamW is recommended for Transformers. Apply to ALL model parameters.\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8) # Added epsilon\n",
        "\n",
        "# Scheduler: Linear warmup and decay (optional but common)\n",
        "num_training_steps = len(train_loader) * EPOCHS\n",
        "num_warmup_steps = int(0.1 * num_training_steps) # 10% warmup is common\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# --- 6. Training Loop ---\n",
        "print(\"\\n--- Starting Fine-Tuning Training ---\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train() # Set model to training mode\n",
        "    epoch_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        # Move batch to device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient Clipping (optional but recommended for fine-tuning)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP_VALUE)\n",
        "\n",
        "        # Optimize and update learning rate\n",
        "        optimizer.step()\n",
        "        scheduler.step() # Update learning rate scheduler\n",
        "\n",
        "        if (i + 1) % 20 == 0: # Print progress more frequently if needed\n",
        "            print(f\"Epoch [{epoch+1}/{EPOCHS}], Batch [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS} Summary:\")\n",
        "    print(f\"  Average Training Loss: {avg_epoch_loss:.4f}\")\n",
        "    print(f\"  Training Accuracy: {epoch_accuracy:.4f}\")\n",
        "\n",
        "# --- 7. Evaluation Loop ---\n",
        "print(\"\\n--- Evaluating on Test Set ---\")\n",
        "model.eval() # Set model to evaluation mode\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculations for evaluation\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# --- 8. Report Results ---\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=['Not Sarcastic', 'Sarcastic'], zero_division=0))\n",
        "\n",
        "macro_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "weighted_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"\\nMacro F1 Score: {macro_f1:.4f}\")\n",
        "print(f\"Weighted F1 Score: {weighted_f1:.4f}\")\n",
        "\n",
        "# --- Optional: Save the fine-tuned model ---\n",
        "# output_dir = \"./bert_lstm_finetuned_model\"\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "# print(f\"\\nSaving model to {output_dir}\")\n",
        "# # Save the entire model (including LSTM/FC layers)\n",
        "# torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
        "# # Save the tokenizer\n",
        "# tokenizer_bert.save_pretrained(output_dir)\n",
        "# # You might also want to save the model configuration if needed\n",
        "# # model.bert.config.save_pretrained(output_dir) # Saves BERT config\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQLPnjAhDq_P",
        "outputId": "48d121bf-54c5-4633-ad9c-482fef940e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading BERT model: bert-base-uncased for fine-tuning\n",
            "BERT hidden size: 768\n",
            "Tokenizing data with BERT tokenizer...\n",
            "Train batches: 1342, Test batches: 448\n",
            "\n",
            "--- Starting Fine-Tuning Training ---\n",
            "Epoch [1/3], Batch [20/1342], Loss: 0.6749, LR: 9.95e-07\n",
            "Epoch [1/3], Batch [40/1342], Loss: 0.6604, LR: 1.99e-06\n",
            "Epoch [1/3], Batch [60/1342], Loss: 0.6800, LR: 2.99e-06\n",
            "Epoch [1/3], Batch [80/1342], Loss: 0.6763, LR: 3.98e-06\n",
            "Epoch [1/3], Batch [100/1342], Loss: 0.6480, LR: 4.98e-06\n",
            "Epoch [1/3], Batch [120/1342], Loss: 0.5820, LR: 5.97e-06\n",
            "Epoch [1/3], Batch [140/1342], Loss: 0.5224, LR: 6.97e-06\n",
            "Epoch [1/3], Batch [160/1342], Loss: 0.4185, LR: 7.96e-06\n",
            "Epoch [1/3], Batch [180/1342], Loss: 0.5503, LR: 8.96e-06\n",
            "Epoch [1/3], Batch [200/1342], Loss: 0.2826, LR: 9.95e-06\n",
            "Epoch [1/3], Batch [220/1342], Loss: 0.5241, LR: 1.09e-05\n",
            "Epoch [1/3], Batch [240/1342], Loss: 0.5004, LR: 1.19e-05\n",
            "Epoch [1/3], Batch [260/1342], Loss: 0.4941, LR: 1.29e-05\n",
            "Epoch [1/3], Batch [280/1342], Loss: 0.2784, LR: 1.39e-05\n",
            "Epoch [1/3], Batch [300/1342], Loss: 0.2953, LR: 1.49e-05\n",
            "Epoch [1/3], Batch [320/1342], Loss: 0.6626, LR: 1.59e-05\n",
            "Epoch [1/3], Batch [340/1342], Loss: 0.3711, LR: 1.69e-05\n",
            "Epoch [1/3], Batch [360/1342], Loss: 0.1513, LR: 1.79e-05\n",
            "Epoch [1/3], Batch [380/1342], Loss: 0.4010, LR: 1.89e-05\n",
            "Epoch [1/3], Batch [400/1342], Loss: 0.0815, LR: 1.99e-05\n",
            "Epoch [1/3], Batch [420/1342], Loss: 0.1170, LR: 1.99e-05\n",
            "Epoch [1/3], Batch [440/1342], Loss: 0.2324, LR: 1.98e-05\n",
            "Epoch [1/3], Batch [460/1342], Loss: 0.1321, LR: 1.97e-05\n",
            "Epoch [1/3], Batch [480/1342], Loss: 0.2821, LR: 1.96e-05\n",
            "Epoch [1/3], Batch [500/1342], Loss: 0.3905, LR: 1.95e-05\n",
            "Epoch [1/3], Batch [520/1342], Loss: 0.1126, LR: 1.93e-05\n",
            "Epoch [1/3], Batch [540/1342], Loss: 0.4315, LR: 1.92e-05\n",
            "Epoch [1/3], Batch [560/1342], Loss: 0.0837, LR: 1.91e-05\n",
            "Epoch [1/3], Batch [580/1342], Loss: 0.2654, LR: 1.90e-05\n",
            "Epoch [1/3], Batch [600/1342], Loss: 0.2290, LR: 1.89e-05\n",
            "Epoch [1/3], Batch [620/1342], Loss: 0.4136, LR: 1.88e-05\n",
            "Epoch [1/3], Batch [640/1342], Loss: 0.1211, LR: 1.87e-05\n",
            "Epoch [1/3], Batch [660/1342], Loss: 0.7147, LR: 1.86e-05\n",
            "Epoch [1/3], Batch [680/1342], Loss: 0.2064, LR: 1.85e-05\n",
            "Epoch [1/3], Batch [700/1342], Loss: 0.0754, LR: 1.84e-05\n",
            "Epoch [1/3], Batch [720/1342], Loss: 0.1903, LR: 1.82e-05\n",
            "Epoch [1/3], Batch [740/1342], Loss: 0.1225, LR: 1.81e-05\n",
            "Epoch [1/3], Batch [760/1342], Loss: 0.3941, LR: 1.80e-05\n",
            "Epoch [1/3], Batch [780/1342], Loss: 0.2421, LR: 1.79e-05\n",
            "Epoch [1/3], Batch [800/1342], Loss: 0.3492, LR: 1.78e-05\n",
            "Epoch [1/3], Batch [820/1342], Loss: 0.6177, LR: 1.77e-05\n",
            "Epoch [1/3], Batch [840/1342], Loss: 0.5591, LR: 1.76e-05\n",
            "Epoch [1/3], Batch [860/1342], Loss: 0.1058, LR: 1.75e-05\n",
            "Epoch [1/3], Batch [880/1342], Loss: 0.0640, LR: 1.74e-05\n",
            "Epoch [1/3], Batch [900/1342], Loss: 0.1160, LR: 1.73e-05\n",
            "Epoch [1/3], Batch [920/1342], Loss: 0.1292, LR: 1.71e-05\n",
            "Epoch [1/3], Batch [940/1342], Loss: 0.0853, LR: 1.70e-05\n",
            "Epoch [1/3], Batch [960/1342], Loss: 0.1693, LR: 1.69e-05\n",
            "Epoch [1/3], Batch [980/1342], Loss: 0.0650, LR: 1.68e-05\n",
            "Epoch [1/3], Batch [1000/1342], Loss: 0.2841, LR: 1.67e-05\n",
            "Epoch [1/3], Batch [1020/1342], Loss: 0.0486, LR: 1.66e-05\n",
            "Epoch [1/3], Batch [1040/1342], Loss: 0.5656, LR: 1.65e-05\n",
            "Epoch [1/3], Batch [1060/1342], Loss: 0.2483, LR: 1.64e-05\n",
            "Epoch [1/3], Batch [1080/1342], Loss: 0.2841, LR: 1.63e-05\n",
            "Epoch [1/3], Batch [1100/1342], Loss: 0.1365, LR: 1.61e-05\n",
            "Epoch [1/3], Batch [1120/1342], Loss: 0.1141, LR: 1.60e-05\n",
            "Epoch [1/3], Batch [1140/1342], Loss: 0.3695, LR: 1.59e-05\n",
            "Epoch [1/3], Batch [1160/1342], Loss: 0.0397, LR: 1.58e-05\n",
            "Epoch [1/3], Batch [1180/1342], Loss: 0.1954, LR: 1.57e-05\n",
            "Epoch [1/3], Batch [1200/1342], Loss: 0.7427, LR: 1.56e-05\n",
            "Epoch [1/3], Batch [1220/1342], Loss: 0.2265, LR: 1.55e-05\n",
            "Epoch [1/3], Batch [1240/1342], Loss: 0.3805, LR: 1.54e-05\n",
            "Epoch [1/3], Batch [1260/1342], Loss: 0.3520, LR: 1.53e-05\n",
            "Epoch [1/3], Batch [1280/1342], Loss: 0.3907, LR: 1.52e-05\n",
            "Epoch [1/3], Batch [1300/1342], Loss: 0.1011, LR: 1.50e-05\n",
            "Epoch [1/3], Batch [1320/1342], Loss: 0.0904, LR: 1.49e-05\n",
            "Epoch [1/3], Batch [1340/1342], Loss: 0.3304, LR: 1.48e-05\n",
            "\n",
            "Epoch 1/3 Summary:\n",
            "  Average Training Loss: 0.3188\n",
            "  Training Accuracy: 0.8622\n",
            "Epoch [2/3], Batch [20/1342], Loss: 0.3193, LR: 1.47e-05\n",
            "Epoch [2/3], Batch [40/1342], Loss: 0.0411, LR: 1.46e-05\n",
            "Epoch [2/3], Batch [60/1342], Loss: 0.4733, LR: 1.45e-05\n",
            "Epoch [2/3], Batch [80/1342], Loss: 0.1598, LR: 1.44e-05\n",
            "Epoch [2/3], Batch [100/1342], Loss: 0.0241, LR: 1.43e-05\n",
            "Epoch [2/3], Batch [120/1342], Loss: 0.0080, LR: 1.42e-05\n",
            "Epoch [2/3], Batch [140/1342], Loss: 0.3253, LR: 1.40e-05\n",
            "Epoch [2/3], Batch [160/1342], Loss: 0.0053, LR: 1.39e-05\n",
            "Epoch [2/3], Batch [180/1342], Loss: 0.2098, LR: 1.38e-05\n",
            "Epoch [2/3], Batch [200/1342], Loss: 0.3344, LR: 1.37e-05\n",
            "Epoch [2/3], Batch [220/1342], Loss: 0.0177, LR: 1.36e-05\n",
            "Epoch [2/3], Batch [240/1342], Loss: 0.1608, LR: 1.35e-05\n",
            "Epoch [2/3], Batch [260/1342], Loss: 0.0094, LR: 1.34e-05\n",
            "Epoch [2/3], Batch [280/1342], Loss: 0.0118, LR: 1.33e-05\n",
            "Epoch [2/3], Batch [300/1342], Loss: 0.0118, LR: 1.32e-05\n",
            "Epoch [2/3], Batch [320/1342], Loss: 0.0077, LR: 1.30e-05\n",
            "Epoch [2/3], Batch [340/1342], Loss: 0.3321, LR: 1.29e-05\n",
            "Epoch [2/3], Batch [360/1342], Loss: 0.2495, LR: 1.28e-05\n",
            "Epoch [2/3], Batch [380/1342], Loss: 0.5353, LR: 1.27e-05\n",
            "Epoch [2/3], Batch [400/1342], Loss: 0.1534, LR: 1.26e-05\n",
            "Epoch [2/3], Batch [420/1342], Loss: 0.3082, LR: 1.25e-05\n",
            "Epoch [2/3], Batch [440/1342], Loss: 0.1484, LR: 1.24e-05\n",
            "Epoch [2/3], Batch [460/1342], Loss: 0.2444, LR: 1.23e-05\n",
            "Epoch [2/3], Batch [480/1342], Loss: 0.0093, LR: 1.22e-05\n",
            "Epoch [2/3], Batch [500/1342], Loss: 0.0567, LR: 1.21e-05\n",
            "Epoch [2/3], Batch [520/1342], Loss: 0.3464, LR: 1.19e-05\n",
            "Epoch [2/3], Batch [540/1342], Loss: 0.6084, LR: 1.18e-05\n",
            "Epoch [2/3], Batch [560/1342], Loss: 0.4460, LR: 1.17e-05\n",
            "Epoch [2/3], Batch [580/1342], Loss: 0.0040, LR: 1.16e-05\n",
            "Epoch [2/3], Batch [600/1342], Loss: 0.0081, LR: 1.15e-05\n",
            "Epoch [2/3], Batch [620/1342], Loss: 0.3564, LR: 1.14e-05\n",
            "Epoch [2/3], Batch [640/1342], Loss: 0.0069, LR: 1.13e-05\n",
            "Epoch [2/3], Batch [660/1342], Loss: 0.0275, LR: 1.12e-05\n",
            "Epoch [2/3], Batch [680/1342], Loss: 0.0121, LR: 1.11e-05\n",
            "Epoch [2/3], Batch [700/1342], Loss: 0.0222, LR: 1.09e-05\n",
            "Epoch [2/3], Batch [720/1342], Loss: 0.6123, LR: 1.08e-05\n",
            "Epoch [2/3], Batch [740/1342], Loss: 0.1742, LR: 1.07e-05\n",
            "Epoch [2/3], Batch [760/1342], Loss: 0.0160, LR: 1.06e-05\n",
            "Epoch [2/3], Batch [780/1342], Loss: 0.5057, LR: 1.05e-05\n",
            "Epoch [2/3], Batch [800/1342], Loss: 0.0066, LR: 1.04e-05\n",
            "Epoch [2/3], Batch [820/1342], Loss: 0.3927, LR: 1.03e-05\n",
            "Epoch [2/3], Batch [840/1342], Loss: 0.4564, LR: 1.02e-05\n",
            "Epoch [2/3], Batch [860/1342], Loss: 0.1587, LR: 1.01e-05\n",
            "Epoch [2/3], Batch [880/1342], Loss: 0.0097, LR: 9.96e-06\n",
            "Epoch [2/3], Batch [900/1342], Loss: 0.5964, LR: 9.85e-06\n",
            "Epoch [2/3], Batch [920/1342], Loss: 0.4308, LR: 9.74e-06\n",
            "Epoch [2/3], Batch [940/1342], Loss: 0.0451, LR: 9.62e-06\n",
            "Epoch [2/3], Batch [960/1342], Loss: 0.0290, LR: 9.51e-06\n",
            "Epoch [2/3], Batch [980/1342], Loss: 0.0181, LR: 9.40e-06\n",
            "Epoch [2/3], Batch [1000/1342], Loss: 0.0057, LR: 9.29e-06\n",
            "Epoch [2/3], Batch [1020/1342], Loss: 0.0141, LR: 9.18e-06\n",
            "Epoch [2/3], Batch [1040/1342], Loss: 0.2043, LR: 9.07e-06\n",
            "Epoch [2/3], Batch [1060/1342], Loss: 0.0514, LR: 8.96e-06\n",
            "Epoch [2/3], Batch [1080/1342], Loss: 0.0101, LR: 8.85e-06\n",
            "Epoch [2/3], Batch [1100/1342], Loss: 0.2351, LR: 8.74e-06\n",
            "Epoch [2/3], Batch [1120/1342], Loss: 0.0072, LR: 8.63e-06\n",
            "Epoch [2/3], Batch [1140/1342], Loss: 0.0036, LR: 8.52e-06\n",
            "Epoch [2/3], Batch [1160/1342], Loss: 0.0270, LR: 8.41e-06\n",
            "Epoch [2/3], Batch [1180/1342], Loss: 0.3107, LR: 8.30e-06\n",
            "Epoch [2/3], Batch [1200/1342], Loss: 0.2340, LR: 8.19e-06\n",
            "Epoch [2/3], Batch [1220/1342], Loss: 0.0035, LR: 8.08e-06\n",
            "Epoch [2/3], Batch [1240/1342], Loss: 0.2864, LR: 7.97e-06\n",
            "Epoch [2/3], Batch [1260/1342], Loss: 0.0050, LR: 7.86e-06\n",
            "Epoch [2/3], Batch [1280/1342], Loss: 0.0098, LR: 7.75e-06\n",
            "Epoch [2/3], Batch [1300/1342], Loss: 0.0115, LR: 7.64e-06\n",
            "Epoch [2/3], Batch [1320/1342], Loss: 0.0055, LR: 7.53e-06\n",
            "Epoch [2/3], Batch [1340/1342], Loss: 0.3106, LR: 7.42e-06\n",
            "\n",
            "Epoch 2/3 Summary:\n",
            "  Average Training Loss: 0.1419\n",
            "  Training Accuracy: 0.9565\n",
            "Epoch [3/3], Batch [20/1342], Loss: 0.0457, LR: 7.30e-06\n",
            "Epoch [3/3], Batch [40/1342], Loss: 0.0058, LR: 7.19e-06\n",
            "Epoch [3/3], Batch [60/1342], Loss: 0.0735, LR: 7.08e-06\n",
            "Epoch [3/3], Batch [80/1342], Loss: 0.0042, LR: 6.96e-06\n",
            "Epoch [3/3], Batch [100/1342], Loss: 0.0023, LR: 6.85e-06\n",
            "Epoch [3/3], Batch [120/1342], Loss: 0.0221, LR: 6.74e-06\n",
            "Epoch [3/3], Batch [140/1342], Loss: 0.0032, LR: 6.63e-06\n",
            "Epoch [3/3], Batch [160/1342], Loss: 0.0067, LR: 6.52e-06\n",
            "Epoch [3/3], Batch [180/1342], Loss: 0.0016, LR: 6.41e-06\n",
            "Epoch [3/3], Batch [200/1342], Loss: 0.2976, LR: 6.30e-06\n",
            "Epoch [3/3], Batch [220/1342], Loss: 0.3312, LR: 6.19e-06\n",
            "Epoch [3/3], Batch [240/1342], Loss: 0.0025, LR: 6.08e-06\n",
            "Epoch [3/3], Batch [260/1342], Loss: 0.0016, LR: 5.97e-06\n",
            "Epoch [3/3], Batch [280/1342], Loss: 0.0117, LR: 5.86e-06\n",
            "Epoch [3/3], Batch [300/1342], Loss: 0.0027, LR: 5.75e-06\n",
            "Epoch [3/3], Batch [320/1342], Loss: 0.0021, LR: 5.64e-06\n",
            "Epoch [3/3], Batch [340/1342], Loss: 0.0017, LR: 5.53e-06\n",
            "Epoch [3/3], Batch [360/1342], Loss: 0.0021, LR: 5.42e-06\n",
            "Epoch [3/3], Batch [380/1342], Loss: 0.0028, LR: 5.31e-06\n",
            "Epoch [3/3], Batch [400/1342], Loss: 0.0062, LR: 5.20e-06\n",
            "Epoch [3/3], Batch [420/1342], Loss: 0.0031, LR: 5.09e-06\n",
            "Epoch [3/3], Batch [440/1342], Loss: 0.2346, LR: 4.98e-06\n",
            "Epoch [3/3], Batch [460/1342], Loss: 0.0018, LR: 4.87e-06\n",
            "Epoch [3/3], Batch [480/1342], Loss: 0.0592, LR: 4.76e-06\n",
            "Epoch [3/3], Batch [500/1342], Loss: 0.0022, LR: 4.65e-06\n",
            "Epoch [3/3], Batch [520/1342], Loss: 0.0628, LR: 4.54e-06\n",
            "Epoch [3/3], Batch [540/1342], Loss: 0.0016, LR: 4.43e-06\n",
            "Epoch [3/3], Batch [560/1342], Loss: 0.0018, LR: 4.32e-06\n",
            "Epoch [3/3], Batch [580/1342], Loss: 0.0020, LR: 4.21e-06\n",
            "Epoch [3/3], Batch [600/1342], Loss: 0.0019, LR: 4.09e-06\n",
            "Epoch [3/3], Batch [620/1342], Loss: 0.0015, LR: 3.98e-06\n",
            "Epoch [3/3], Batch [640/1342], Loss: 0.0028, LR: 3.87e-06\n",
            "Epoch [3/3], Batch [660/1342], Loss: 0.0021, LR: 3.76e-06\n",
            "Epoch [3/3], Batch [680/1342], Loss: 0.0034, LR: 3.65e-06\n",
            "Epoch [3/3], Batch [700/1342], Loss: 0.0016, LR: 3.54e-06\n",
            "Epoch [3/3], Batch [720/1342], Loss: 0.0021, LR: 3.43e-06\n",
            "Epoch [3/3], Batch [740/1342], Loss: 0.0019, LR: 3.32e-06\n",
            "Epoch [3/3], Batch [760/1342], Loss: 0.0050, LR: 3.21e-06\n",
            "Epoch [3/3], Batch [780/1342], Loss: 0.0017, LR: 3.10e-06\n",
            "Epoch [3/3], Batch [800/1342], Loss: 0.0028, LR: 2.99e-06\n",
            "Epoch [3/3], Batch [820/1342], Loss: 0.0984, LR: 2.88e-06\n",
            "Epoch [3/3], Batch [840/1342], Loss: 0.0069, LR: 2.77e-06\n",
            "Epoch [3/3], Batch [860/1342], Loss: 0.0031, LR: 2.66e-06\n",
            "Epoch [3/3], Batch [880/1342], Loss: 0.0016, LR: 2.55e-06\n",
            "Epoch [3/3], Batch [900/1342], Loss: 0.1910, LR: 2.44e-06\n",
            "Epoch [3/3], Batch [920/1342], Loss: 0.3497, LR: 2.33e-06\n",
            "Epoch [3/3], Batch [940/1342], Loss: 0.0020, LR: 2.22e-06\n",
            "Epoch [3/3], Batch [960/1342], Loss: 0.0124, LR: 2.11e-06\n",
            "Epoch [3/3], Batch [980/1342], Loss: 0.0372, LR: 2.00e-06\n",
            "Epoch [3/3], Batch [1000/1342], Loss: 0.0081, LR: 1.89e-06\n",
            "Epoch [3/3], Batch [1020/1342], Loss: 0.0930, LR: 1.78e-06\n",
            "Epoch [3/3], Batch [1040/1342], Loss: 0.0016, LR: 1.67e-06\n",
            "Epoch [3/3], Batch [1060/1342], Loss: 0.0412, LR: 1.56e-06\n",
            "Epoch [3/3], Batch [1080/1342], Loss: 0.0220, LR: 1.45e-06\n",
            "Epoch [3/3], Batch [1100/1342], Loss: 0.0040, LR: 1.34e-06\n",
            "Epoch [3/3], Batch [1120/1342], Loss: 0.0016, LR: 1.23e-06\n",
            "Epoch [3/3], Batch [1140/1342], Loss: 0.0348, LR: 1.11e-06\n",
            "Epoch [3/3], Batch [1160/1342], Loss: 0.0023, LR: 1.00e-06\n",
            "Epoch [3/3], Batch [1180/1342], Loss: 0.0023, LR: 8.94e-07\n",
            "Epoch [3/3], Batch [1200/1342], Loss: 0.2564, LR: 7.84e-07\n",
            "Epoch [3/3], Batch [1220/1342], Loss: 0.0019, LR: 6.73e-07\n",
            "Epoch [3/3], Batch [1240/1342], Loss: 0.0310, LR: 5.63e-07\n",
            "Epoch [3/3], Batch [1260/1342], Loss: 0.0061, LR: 4.53e-07\n",
            "Epoch [3/3], Batch [1280/1342], Loss: 0.0025, LR: 3.42e-07\n",
            "Epoch [3/3], Batch [1300/1342], Loss: 0.0981, LR: 2.32e-07\n",
            "Epoch [3/3], Batch [1320/1342], Loss: 0.0020, LR: 1.21e-07\n",
            "Epoch [3/3], Batch [1340/1342], Loss: 0.2802, LR: 1.10e-08\n",
            "\n",
            "Epoch 3/3 Summary:\n",
            "  Average Training Loss: 0.0620\n",
            "  Training Accuracy: 0.9843\n",
            "\n",
            "--- Evaluating on Test Set ---\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Not Sarcastic       0.91      0.95      0.93      3746\n",
            "    Sarcastic       0.94      0.90      0.92      3409\n",
            "\n",
            "     accuracy                           0.93      7155\n",
            "    macro avg       0.93      0.93      0.93      7155\n",
            " weighted avg       0.93      0.93      0.93      7155\n",
            "\n",
            "\n",
            "Macro F1 Score: 0.9274\n",
            "Weighted F1 Score: 0.9276\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval/Train"
      ],
      "metadata": {
        "id": "kcVdk9VPNtDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, verbose, device):\n",
        "  with torch.no_grad():\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "    y = []\n",
        "    for input, output in test_loader:\n",
        "      input = input.to(device)\n",
        "      output = output.to(device)\n",
        "      preds = torch.argmax(model(input), dim=1)\n",
        "      y_pred.extend(preds.cpu().numpy())\n",
        "      y.extend(output.cpu().numpy())\n",
        "    if verbose:\n",
        "      pass\n",
        "      # print(classification_report(y, y_pred))\n",
        "      # print(confusion_matrix(y, y_pred))\n",
        "    macro_f1_score = f1_score(y, y_pred, average='macro')\n",
        "    print(f\"Macro Test F1: {macro_f1_score:.4f}\")\n",
        "    return macro_f1_score\n",
        "\n",
        "evaluate(model, test_loader, True, device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vHGHNh4JVsNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cfceaf-cc07-4713-8702-78db54a01e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro Test F1: 0.5493\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5492632629560703"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
        "patience = 8\n",
        "\n",
        "def train(model, train_loader, device, epochs=100):\n",
        "    model.to(device)\n",
        "    best_test_f1 = 0\n",
        "    curr = 0\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        y = []\n",
        "        y_p = []\n",
        "        running_loss = 0\n",
        "\n",
        "        for input, output in train_loader:\n",
        "            input = input.to(device)\n",
        "            output = output.to(device)\n",
        "\n",
        "            y_pred = model(input)\n",
        "            y_pred_labels = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "            y_p.extend(y_pred_labels.cpu().numpy())\n",
        "            y.extend(output.cpu().numpy())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(y_pred, output)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        macro_train_f1 = f1_score(y, y_p, average='macro')\n",
        "        print(f\"\\nEpoch {i+1}/{epochs}\")\n",
        "        print(f\"Train Loss: {running_loss:.4f}\")\n",
        "        print(f\"Macro Training F1: {macro_train_f1:.4f}\")\n",
        "\n",
        "        # Evaluate on test set\n",
        "        macro_test_f1 = evaluate(model, test_loader, True, device)\n",
        "        scheduler.step(macro_test_f1)\n",
        "\n",
        "        # Print current learning rate\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
        "\n",
        "        if macro_test_f1 > best_test_f1:\n",
        "          curr = 0\n",
        "          best_test_f1 = macro_test_f1\n",
        "          print(\"New best model! Saving...\")\n",
        "          torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        else:\n",
        "          curr += 1\n",
        "          if curr >= patience:\n",
        "            print(\"Early Stopping..\")\n",
        "            break\n",
        "\n",
        "\n",
        "train(model, train_loader, device)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pv7IJZZ7WQpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a8a1e8-61e7-4c39-e726-3bc9cac82a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/100\n",
            "Train Loss: 61.0082\n",
            "Macro Training F1: 0.9700\n",
            "Macro Test F1: 0.9264\n",
            "Current Learning Rate: 0.001000\n",
            "New best model! Saving...\n",
            "\n",
            "Epoch 2/100\n",
            "Train Loss: 53.7361\n",
            "Macro Training F1: 0.9726\n",
            "Macro Test F1: 0.9272\n",
            "Current Learning Rate: 0.001000\n",
            "New best model! Saving...\n",
            "\n",
            "Epoch 3/100\n",
            "Train Loss: 49.9957\n",
            "Macro Training F1: 0.9749\n",
            "Macro Test F1: 0.9283\n",
            "Current Learning Rate: 0.001000\n",
            "New best model! Saving...\n",
            "\n",
            "Epoch 4/100\n",
            "Train Loss: 47.3907\n",
            "Macro Training F1: 0.9765\n",
            "Macro Test F1: 0.9269\n",
            "Current Learning Rate: 0.001000\n",
            "\n",
            "Epoch 5/100\n",
            "Train Loss: 44.5494\n",
            "Macro Training F1: 0.9774\n",
            "Macro Test F1: 0.9278\n",
            "Current Learning Rate: 0.001000\n",
            "\n",
            "Epoch 6/100\n",
            "Train Loss: 41.6076\n",
            "Macro Training F1: 0.9780\n",
            "Macro Test F1: 0.9263\n",
            "Current Learning Rate: 0.001000\n",
            "\n",
            "Epoch 7/100\n",
            "Train Loss: 39.7610\n",
            "Macro Training F1: 0.9792\n",
            "Macro Test F1: 0.9276\n",
            "Current Learning Rate: 0.000500\n",
            "\n",
            "Epoch 8/100\n",
            "Train Loss: 35.0683\n",
            "Macro Training F1: 0.9827\n",
            "Macro Test F1: 0.9275\n",
            "Current Learning Rate: 0.000500\n",
            "\n",
            "Epoch 9/100\n",
            "Train Loss: 33.6490\n",
            "Macro Training F1: 0.9836\n",
            "Macro Test F1: 0.9275\n",
            "Current Learning Rate: 0.000500\n",
            "\n",
            "Epoch 10/100\n",
            "Train Loss: 32.9272\n",
            "Macro Training F1: 0.9841\n",
            "Macro Test F1: 0.9274\n",
            "Current Learning Rate: 0.000500\n",
            "\n",
            "Epoch 11/100\n",
            "Train Loss: 31.9617\n",
            "Macro Training F1: 0.9845\n",
            "Macro Test F1: 0.9300\n",
            "Current Learning Rate: 0.000500\n",
            "New best model! Saving...\n",
            "\n",
            "Epoch 12/100\n",
            "Train Loss: 31.3089\n",
            "Macro Training F1: 0.9849\n",
            "Macro Test F1: 0.9289\n",
            "Current Learning Rate: 0.000500\n",
            "\n",
            "Epoch 13/100\n",
            "Train Loss: 30.4901\n",
            "Macro Training F1: 0.9849\n",
            "Macro Test F1: 0.9278\n",
            "Current Learning Rate: 0.000500\n",
            "\n",
            "Epoch 14/100\n",
            "Train Loss: 29.7104\n",
            "Macro Training F1: 0.9858\n",
            "Macro Test F1: 0.9284\n",
            "Current Learning Rate: 0.000500\n",
            "\n",
            "Epoch 15/100\n",
            "Train Loss: 29.1273\n",
            "Macro Training F1: 0.9860\n",
            "Macro Test F1: 0.9283\n",
            "Current Learning Rate: 0.000250\n",
            "\n",
            "Epoch 16/100\n",
            "Train Loss: 26.8767\n",
            "Macro Training F1: 0.9874\n",
            "Macro Test F1: 0.9279\n",
            "Current Learning Rate: 0.000250\n",
            "\n",
            "Epoch 17/100\n",
            "Train Loss: 26.5071\n",
            "Macro Training F1: 0.9876\n",
            "Macro Test F1: 0.9281\n",
            "Current Learning Rate: 0.000250\n",
            "\n",
            "Epoch 18/100\n",
            "Train Loss: 26.0660\n",
            "Macro Training F1: 0.9886\n",
            "Macro Test F1: 0.9282\n",
            "Current Learning Rate: 0.000250\n",
            "\n",
            "Epoch 19/100\n",
            "Train Loss: 25.8541\n",
            "Macro Training F1: 0.9887\n",
            "Macro Test F1: 0.9287\n",
            "Current Learning Rate: 0.000125\n",
            "Early Stopping..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tmp = SimpleNN(X_train_combined.shape[1])\n",
        "#tmp = RNN(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True).to(device)\n",
        "tmp = LSTM(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True, bidirectional=True, freeze=False,num_layers=1).to(device)\n",
        "#tmp = LSTMWithAttention(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True, bidirectional=False, freeze=False,num_layers=1).to(device)\n",
        "#tmp = GRU(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True, bidirectional=True, freeze=False,num_layers=1).to(device)\n",
        "tmp.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "evaluate(tmp, test_loader, True, device)"
      ],
      "metadata": {
        "id": "W87UWPB6ZSnu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "c30085e9-d269-4fc0-ab6b-7ea6d6ed5633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for LSTM:\n\tMissing key(s) in state_dict: \"embedding.weight\", \"lstm.weight_ih_l0\", \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"lstm.weight_ih_l0_reverse\", \"lstm.weight_hh_l0_reverse\", \"lstm.bias_ih_l0_reverse\", \"lstm.bias_hh_l0_reverse\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"fc1.0.weight\", \"fc1.0.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-2d5d32ea016b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#tmp = LSTMWithAttention(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True, bidirectional=False, freeze=False,num_layers=1).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#tmp = GRU(vocab_size, embedding_dim, hidden_dim=hidden_dim, pre_trained_embed=True, bidirectional=True, freeze=False,num_layers=1).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTM:\n\tMissing key(s) in state_dict: \"embedding.weight\", \"lstm.weight_ih_l0\", \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"lstm.weight_ih_l0_reverse\", \"lstm.weight_hh_l0_reverse\", \"lstm.bias_ih_l0_reverse\", \"lstm.bias_hh_l0_reverse\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"fc1.0.weight\", \"fc1.0.bias\". "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WPNIYJwLNc4h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}