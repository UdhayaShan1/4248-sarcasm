[nltk_data] Downloading package stopwords to[nltk_data]     /home/y/yuchenbo/nltk_data...[nltk_data]   Package stopwords is already up-to-date![nltk_data] Downloading package wordnet to[nltk_data]     /home/y/yuchenbo/nltk_data...[nltk_data]   Package wordnet is already up-to-date![nltk_data] Downloading package punkt to /home/y/yuchenbo/nltk_data...[nltk_data]   Package punkt is already up-to-date![nltk_data] Downloading package averaged_perceptron_tagger to[nltk_data]     /home/y/yuchenbo/nltk_data...[nltk_data]   Package averaged_perceptron_tagger is already up-to-[nltk_data]       date![nltk_data] Downloading package averaged_perceptron_tagger_eng to[nltk_data]     /home/y/yuchenbo/nltk_data...[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-[nltk_data]       date![nltk_data] Downloading package punkt_tab to[nltk_data]     /home/y/yuchenbo/nltk_data...[nltk_data]   Package punkt_tab is already up-to-date![nltk_data] Downloading package averaged_perceptron_tagger to[nltk_data]     /home/y/yuchenbo/nltk_data...[nltk_data]   Package averaged_perceptron_tagger is already up-to-[nltk_data]       date![nltk_data] Downloading package stopwords to[nltk_data]     /home/y/yuchenbo/nltk_data...[nltk_data]   Package stopwords is already up-to-date![nltk_data] Downloading package wordnet to[nltk_data]     /home/y/yuchenbo/nltk_data...[nltk_data]   Package wordnet is already up-to-date![nltk_data] Downloading package punkt to /home/y/yuchenbo/nltk_data...[nltk_data]   Package punkt is already up-to-date!2025-04-09 19:44:08.482239: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.2025-04-09 19:44:08.858748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.  Processed batch 50/895  Processed batch 100/895  Processed batch 150/895  Processed batch 200/895  Processed batch 250/895  Processed batch 300/895  Processed batch 350/895  Processed batch 400/895  Processed batch 450/895  Processed batch 500/895  Processed batch 550/895  Processed batch 600/895  Processed batch 650/895  Processed batch 700/895  Processed batch 750/895  Processed batch 800/895  Processed batch 850/895(28619, 768)Extracting linguistic features...Linguistic features shape: (28619, 17)Combining BERT [CLS] and linguistic features...Combined BERT+Ling shape: (28619, 785)Splitting data into train/test sets...Train features shape: (21464, 785), Test features shape: (7155, 785)Scaling combined BERT+Ling features...Scaled features shape (sparse): (21464, 785)Generating TF-IDF features...TF-IDF Train shape: (21464, 23197)TF-IDF Test shape: (7155, 23197)Combining TF-IDF and Scaled (BERT+Ling) features...Final Combined Train shape: (21464, 23982)Final Combined Test shape: (7155, 23982)Training Logistic Regression model...Evaluating Logistic Regression model...Classification Report:              precision    recall  f1-score   support           0       0.89      0.89      0.89      3746           1       0.88      0.88      0.88      3409    accuracy                           0.89      7155   macro avg       0.89      0.89      0.89      7155weighted avg       0.89      0.89      0.89      7155Confusion Matrix:[[3348  398] [ 396 3013]]Macro F1 Score: 0.8888--- Script Finished ---%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Trainable parameters: 1,538 (0.0%)Epoch 1/100At epoch  0Evaluation Results:              precision    recall  f1-score   support           0       0.55      0.96      0.70      3730           1       0.77      0.15      0.25      3425    accuracy                           0.57      7155   macro avg       0.66      0.56      0.48      7155weighted avg       0.66      0.57      0.49      7155Macro F1 score: 0.47707076704945983Epoch 2/100At epoch  1Evaluation Results:              precision    recall  f1-score   support           0       0.66      0.84      0.74      3730           1       0.75      0.52      0.61      3425    accuracy                           0.69      7155   macro avg       0.70      0.68      0.67      7155weighted avg       0.70      0.69      0.68      7155Macro F1 score: 0.6749449685609564Epoch 3/100At epoch  2Evaluation Results:              precision    recall  f1-score   support           0       0.59      0.96      0.73      3730           1       0.85      0.27      0.41      3425    accuracy                           0.63      7155   macro avg       0.72      0.62      0.57      7155weighted avg       0.72      0.63      0.58      7155Macro F1 score: 0.5716182177600784Epoch 4/100At epoch  3Evaluation Results:              precision    recall  f1-score   support           0       0.65      0.90      0.75      3730           1       0.80      0.46      0.59      3425    accuracy                           0.69      7155   macro avg       0.72      0.68      0.67      7155weighted avg       0.72      0.69      0.67      7155Macro F1 score: 0.6690492810901902Epoch 5/100At epoch  4Evaluation Results:              precision    recall  f1-score   support           0       0.65      0.90      0.76      3730           1       0.81      0.48      0.60      3425    accuracy                           0.70      7155   macro avg       0.73      0.69      0.68      7155weighted avg       0.73      0.70      0.68      7155Macro F1 score: 0.6789133515864336Epoch 6/100At epoch  5Evaluation Results:              precision    recall  f1-score   support           0       0.65      0.90      0.76      3730           1       0.81      0.48      0.60      3425    accuracy                           0.70      7155   macro avg       0.73      0.69      0.68      7155weighted avg       0.73      0.70      0.68      7155Macro F1 score: 0.67838818992729Epoch 7/100At epoch  6Evaluation Results:              precision    recall  f1-score   support           0       0.65      0.91      0.76      3730           1       0.82      0.47      0.60      3425    accuracy                           0.70      7155   macro avg       0.74      0.69      0.68      7155weighted avg       0.73      0.70      0.68      7155Macro F1 score: 0.6772017445350453Epoch 8/100At epoch  7Evaluation Results:              precision    recall  f1-score   support           0       0.67      0.88      0.76      3730           1       0.81      0.53      0.64      3425    accuracy                           0.71      7155   macro avg       0.74      0.71      0.70      7155weighted avg       0.74      0.71      0.70      7155Macro F1 score: 0.7004440480068855Epoch 9/100At epoch  39Evaluation Results:              precision    recall  f1-score   support           0       0.74      0.85      0.79      3730           1       0.80      0.67      0.73      3425    accuracy                           0.76      7155   macro avg       0.77      0.76      0.76      7155weighted avg       0.77      0.76      0.76      7155Macro F1 score: 0.7610833429700918Epoch 41/100